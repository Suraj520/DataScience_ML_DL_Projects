{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About\n",
    "> Mutual Information\n",
    "\n",
    "Mutual information is a measure of the amount of information that two random variables share. It measures how much knowing one variable can tell us about the other variable. \n",
    "\n",
    "\n",
    "The mutual information between two random variables X and Y is defined as follows:\n",
    "\n",
    "I(X; Y) = H(X) - H(X|Y)\n",
    "\n",
    "where H(X) is the entropy of X and H(X|Y) is the conditional entropy of X given Y.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One use case of mutual information is feature selection in machine learning. It can be used to identify the most informative features in a dataset. By calculating the mutual information between each feature and the target variable, we can select the features that have the highest mutual information and use them for prediction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# load the wine dataset\n",
    "data = load_wine()\n",
    "\n",
    "# split the dataset into features and target variable\n",
    "X = data.data[:, :2]  # select the first two features\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47065576 0.29075225]\n"
     ]
    }
   ],
   "source": [
    "# calculate mutual information scores\n",
    "mi_scores = mutual_info_classif(X, y)\n",
    "\n",
    "# print the mutual information scores\n",
    "print(mi_scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the first feature has a higher mutual information score than the second feature, indicating that it is more informative in predicting the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
