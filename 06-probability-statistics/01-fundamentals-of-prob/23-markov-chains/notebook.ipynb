{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About\n",
    "> Markov chains\n",
    "\n",
    "Markov Chains are a mathematical framework for modeling systems that transition between different states over time. It is a stochastic process that satisfies the Markov property, which means that the probability of transitioning to the next state depends only on the current state, and not on any past states.\n",
    "\n",
    "Markov Chains have a wide range of applications, such as in weather forecasting, finance, biology, and computer science. For example, Markov Chains can be used to model the weather by representing the weather as different states (e.g., sunny, cloudy, rainy), and modeling the transitions between these states based on historical weather data.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to model the weather using a Markov Chain with three states: sunny, cloudy, and rainy. We can represent the transitions between these states using a transition probability matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 1 0 0 0 2 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# transition probability matrix -  probability of transitioning from state i to state j\n",
    "P = np.array([[0.7, 0.2, 0.1],\n",
    "              [0.3, 0.5, 0.2],\n",
    "              [0.1, 0.3, 0.6]])\n",
    "\n",
    "# initial state distribution\n",
    "pi = np.array([0.4, 0.3, 0.3]) #the probabilities of starting in each state.\n",
    "\n",
    "# simulate the Markov Chain for 10 steps\n",
    "N = 10\n",
    "states = np.zeros(N, dtype=int)\n",
    "states[0] = np.random.choice(3, p=pi)\n",
    "for t in range(1, N):\n",
    "    states[t] = np.random.choice(3, p=P[states[t-1]])\n",
    "    \n",
    "print(states)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Markov Chain in this example has three possible states: 0, 1, and 2. The output represents a simulated sequence of the states that the Markov Chain transitions through over ten time steps, starting from an initial state of 0.\n",
    "\n",
    "Each entry in the sequence corresponds to the state of the Markov Chain at that time step. For example, the first entry 0 indicates that the Markov Chain is in state 0 at time step 0. The second entry 0 indicates that the Markov Chain is still in state 0 at time step 1. The third entry 1 indicates that the Markov Chain transitioned to state 1 at time step 2, and so on.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
