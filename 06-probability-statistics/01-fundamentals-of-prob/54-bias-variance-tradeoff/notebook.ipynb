{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About\n",
    "> Bias Variance Trade off\n",
    "\n",
    "The bias-variance tradeoff is a fundamental concept in machine learning that describes the relationship between the complexity of a model and its ability to generalize to new data. It refers to the tradeoff between the model's ability to fit the training data (bias) and its ability to generalize to new data (variance).\n",
    "\n",
    "Bias refers to the error that is introduced by approximating a real-life problem with a simplified model. A high bias model is one that is too simple to capture the underlying patterns in the data and tends to underfit. On the other hand, variance refers to the error that is introduced by the model's sensitivity to small fluctuations in the training data. A high variance model is one that is too complex and tends to overfit the training data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
