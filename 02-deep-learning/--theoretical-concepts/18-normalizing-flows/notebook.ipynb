{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### About\n",
    "\n",
    "> Normalizing flows\n",
    "\n",
    "Normalized flow is a class of generative models in deep learning that aims to learn bijective mappings between simple distributions (such as Gaussian distributions) and complex distributions (such as high-dimensional datasets). The main idea is to use a series of reversible transformations or \"flows\" to transform samples from simple to complex distributions. \n",
    "\n",
    "Mathematically, the normalization flow consists of a sequence of reversible transformations denoted T1, T2, ..., Tn, where each transformation maps a data point x in the input space to a new data point y in the transformed space. The forward transformation is expressed as y = T(x), and the inverse transformation is expressed as x = T^(-1)(y), where T^(-1) is the inverse of T. \n",
    "\n",
    "Each transformation T is usually designed to be computationally efficient and must have a tractable Jacobian that defines the locally linearized Jacobian describing the transformation. This is important because it efficiently computes the probability density function (PDF) of the transformed data points, which is required for generative modeling. \n",
    "\n",
    "During training, a normalized flow is trained to minimize the difference between the data distribution and the model distribution. This is usually done using maximum likelihood estimation (MLE) or variational methods, where the model is optimized to maximize the likelihood of the training data or minimize the difference between the model distribution and the data distribution.\n",
    "\n",
    "Normalized flows have several advantages, including the ability to generate high-quality samples from complex distributions, the ability to perform accurate probability calculations, and the ability to make inferential inferences (such as computing posterior probabilities). However, they also face some challenges, such as the need for reversible and computationally efficient transformations and the possibility of overfitting due to the large number of parameters of the depth flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
