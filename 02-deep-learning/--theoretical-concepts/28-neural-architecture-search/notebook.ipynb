{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About\n",
    "\n",
    "> Neural Architecture Search\n",
    "\n",
    "Neural Architecture Search (NAS) is the process of using machine learning techniques to automatically design the best neural network architecture for a given task, such as image classification, object recognition, or speech recognition. NAS aims to automate the process of designing neural network architectures, which is usually done by human experts through trial and error. \n",
    "\n",
    "The goal of NAS is to find the optimal neural network architecture that can achieve high performance in the target task while reducing the computational cost and model size. NAS algorithms typically search a large number of possible network architectures and use various techniques such as reinforcement learning, genetic algorithms, or evolutionary algorithms to automatically discover promising architectures. \n",
    "\n",
    "Following are the general steps of the NAS process.\n",
    "\n",
    "1. Define the search domain. This step specifies the set of possible neural network architectures that the NAS algorithm will search for. A search space typically includes different types of layers, such as convolutional, pooling, and fully connected layers, and their hyperparameters, such as filter size, number of filters, and activation functions.\n",
    "\n",
    "2. Architecture Search: The NAS algorithm searches a given search area to find promising neural network architectures. This can be done using various methods such as random search, grid search or more advanced methods such as reinforcement learning, genetic algorithms or evolutionary algorithms. \n",
    "\n",
    "3. Evaluate architectures: After generating a set of candidate architectures, they must be evaluated on the target task to determine their performance. This is typically done by training and evaluating the dataset architecture for the target task, such as training datasets for image classification or speech datasets for speech recognition.\n",
    "\n",
    "4. Update search strategy: Based on the evaluation results, the NAS algorithm updates its search strategy to generate a new set of candidate architectures. This may involve exploiting promising architectures by generating their variants or exploring new regions of the search space to discover potentially better architectures. \n",
    "\n",
    "5. Iterative process: The NAS process is usually iterative, where the algorithm searches, evaluates, and updates its search strategy several times until a satisfactory architecture is found or a predefined stopping criterion is met. \n",
    "\n",
    "Once the NAS process is complete, the resulting discovered architecture can be used to train a neural network model, which can then be used to make inferences about the target task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-22 06:10:03.066954: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-22 06:10:03.121167: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-22 06:10:03.122144: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-22 06:10:04.720618: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space for NAS\n",
    "search_space = [\n",
    "    {'type': 'conv', 'filters': 16, 'kernel_size': (3, 3)},\n",
    "    {'type': 'conv', 'filters': 32, 'kernel_size': (3, 3)},\n",
    "    {'type': 'pool', 'pool_size': (2, 2)},\n",
    "    {'type': 'flatten'},\n",
    "    {'type': 'dense', 'units': 64, 'activation': 'relu'},\n",
    "    {'type': 'dense', 'units': 10, 'activation': 'softmax'}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random architecture from the search space\n",
    "def generate_random_architecture(search_space):\n",
    "    model = Sequential()\n",
    "    for layer in search_space:\n",
    "        if layer['type'] == 'conv':\n",
    "            model.add(Conv2D(filters=layer['filters'], kernel_size=layer['kernel_size'], activation='relu', padding='same'))\n",
    "        elif layer['type'] == 'pool':\n",
    "            model.add(MaxPooling2D(pool_size=layer['pool_size']))\n",
    "        elif layer['type'] == 'flatten':\n",
    "            model.add(Flatten())\n",
    "        elif layer['type'] == 'dense':\n",
    "            model.add(Dense(units=layer['units'], activation=layer['activation']))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the accuracy of a given architecture\n",
    "def evaluate_architecture(model, x_train, y_train, x_test, y_test):\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, batch_size=128, epochs=1, verbose=1)\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    return score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 38s 78ms/step - loss: 0.2083 - accuracy: 0.9409\n",
      "Architecture 1, Accuracy: 0.9779000282287598\n",
      "469/469 [==============================] - 41s 84ms/step - loss: 0.1914 - accuracy: 0.9439\n",
      "Architecture 2, Accuracy: 0.9800999760627747\n",
      "469/469 [==============================] - 40s 83ms/step - loss: 0.2188 - accuracy: 0.9362\n",
      "Architecture 3, Accuracy: 0.9781000018119812\n",
      "469/469 [==============================] - 41s 85ms/step - loss: 0.1979 - accuracy: 0.9429\n",
      "Architecture 4, Accuracy: 0.9779000282287598\n",
      "469/469 [==============================] - 49s 100ms/step - loss: 0.2272 - accuracy: 0.9344\n",
      "Architecture 5, Accuracy: 0.9750000238418579\n",
      "469/469 [==============================] - 45s 92ms/step - loss: 0.2166 - accuracy: 0.9373\n",
      "Architecture 6, Accuracy: 0.9800999760627747\n",
      "469/469 [==============================] - 42s 87ms/step - loss: 0.2109 - accuracy: 0.9378\n",
      "Architecture 7, Accuracy: 0.9745000004768372\n",
      "469/469 [==============================] - 40s 82ms/step - loss: 0.2146 - accuracy: 0.9373\n",
      "Architecture 8, Accuracy: 0.9781000018119812\n",
      "469/469 [==============================] - 40s 82ms/step - loss: 0.2101 - accuracy: 0.9408\n",
      "Architecture 9, Accuracy: 0.9796000123023987\n",
      "469/469 [==============================] - 42s 86ms/step - loss: 0.2275 - accuracy: 0.9343\n",
      "Architecture 10, Accuracy: 0.9761999845504761\n",
      "Best Model Accuracy: 0.9800999760627747\n"
     ]
    }
   ],
   "source": [
    "# Perform NAS\n",
    "best_accuracy = 0\n",
    "best_model = None\n",
    "num_architectures = 10  # number of architectures to generate and evaluate\n",
    "for i in range(num_architectures):\n",
    "    architecture = generate_random_architecture(search_space)\n",
    "    accuracy = evaluate_architecture(architecture, x_train, y_train, x_test, y_test)\n",
    "    print(f'Architecture {i+1}, Accuracy: {accuracy}')\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = architecture\n",
    "\n",
    "# Print the best model's accuracy\n",
    "print(f'Best Model Accuracy: {best_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
