{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About\n",
    "\n",
    "> Deep neural networks\n",
    "\n",
    "A deep neural network (DNN) is a neural network with multiple hidden layers between the input and output layers. Each hidden layer contains a set of neurons that transforms the input into a higher-level representation. The output of one hidden layer serves as the input to the next hidden layer, allowing more complex representations to be learned.\n",
    "\n",
    "Mathematically, the output of a deep neural network can be expressed as:\n",
    "\n",
    "```\n",
    "Z[1] = W[1]*X + b[1]\n",
    "A[1] = g[1] (Z[1])\n",
    "Z[2] = W[2]*A[1] + b[2]\n",
    "A[2] = g[2] (Z[2])\n",
    "... Z[L] = W[L]*A[L-1] + b[L]\n",
    "A[L] = g[L] (Z[L])\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "where X is the input vector, W is the weight matrix, b is the bias vector, Z is the weighted sum of the inputs, g() is the activation function, and L is the number of layers in the network.\n",
    "\n",
    "The output A[L] from the last hidden layer is used as input to the output layer. The choice of the activation function g[L] depends on the task at hand. For example, if the task is binary classification, we can use sigmoid activation function, while for multi-class classification, we can use softmax activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-22 00:29:16.857617: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-22 00:29:16.922199: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-22 00:29:16.922905: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-22 00:29:18.366686: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-22 00:29:22.875785: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-22 00:29:22.877049: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Creating a deep neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(units=4, input_dim=2, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 8ms/step - loss: 0.7869 - accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7853 - accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7843 - accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7835 - accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7831 - accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7824 - accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7813 - accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7811 - accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7801 - accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7798 - accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7788 - accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7780 - accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7776 - accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7768 - accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7761 - accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7758 - accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7748 - accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7745 - accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7738 - accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7729 - accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7723 - accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7717 - accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7713 - accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7703 - accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7697 - accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7691 - accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7684 - accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7679 - accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7673 - accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7667 - accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7659 - accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7651 - accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7647 - accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7640 - accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7634 - accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7630 - accuracy: 0.5000\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7619 - accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7613 - accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7608 - accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7600 - accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7593 - accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7587 - accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7580 - accuracy: 0.5000\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7575 - accuracy: 0.5000\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7566 - accuracy: 0.5000\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7561 - accuracy: 0.5000\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7552 - accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7545 - accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7538 - accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7530 - accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7524 - accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7517 - accuracy: 0.5000\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7508 - accuracy: 0.5000\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7505 - accuracy: 0.5000\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7496 - accuracy: 0.5000\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7486 - accuracy: 0.5000\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7482 - accuracy: 0.5000\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7472 - accuracy: 0.5000\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7463 - accuracy: 0.5000\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7457 - accuracy: 0.5000\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7451 - accuracy: 0.5000\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7444 - accuracy: 0.5000\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7435 - accuracy: 0.5000\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7426 - accuracy: 0.5000\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7419 - accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7411 - accuracy: 0.5000\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7402 - accuracy: 0.5000\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7394 - accuracy: 0.5000\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7386 - accuracy: 0.5000\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7380 - accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7370 - accuracy: 0.5000\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7365 - accuracy: 0.5000\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7346 - accuracy: 0.5000\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7339 - accuracy: 0.5000\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7332 - accuracy: 0.5000\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7323 - accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7318 - accuracy: 0.5000\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7307 - accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7299 - accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7290 - accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7282 - accuracy: 0.5000\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7274 - accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7266 - accuracy: 0.5000\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7258 - accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7249 - accuracy: 0.5000\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7239 - accuracy: 0.5000\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7232 - accuracy: 0.5000\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7225 - accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7215 - accuracy: 0.5000\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7205 - accuracy: 0.5000\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7197 - accuracy: 0.5000\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7189 - accuracy: 0.5000\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7185 - accuracy: 0.5000\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7172 - accuracy: 0.5000\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7165 - accuracy: 0.5000\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7155 - accuracy: 0.5000\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7148 - accuracy: 0.5000\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7138 - accuracy: 0.5000\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7130 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe22c14e940>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([0, 1, 1, 0])\n",
    "model.fit(X, y, epochs=100, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 161ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predicting new data\n",
    "new_X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "predictions = model.predict(new_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.51089394]\n",
      " [0.5697858 ]\n",
      " [0.3770278 ]\n",
      " [0.44934863]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
