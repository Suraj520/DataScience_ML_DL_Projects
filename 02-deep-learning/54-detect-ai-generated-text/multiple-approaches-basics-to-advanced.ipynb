{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":61542,"databundleVersionId":6888007,"sourceType":"competition"},{"sourceId":2624724,"sourceType":"datasetVersion","datasetId":1595713}],"dockerImageVersionId":30587,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"background-color:#5D73F2; color:#19180F; font-size:40px; font-family:Arial; padding:10px; border: 5px solid #19180F; border-radius:10px\"> Multiple approaches </div>\n<div style=\"background-color:#A8B4F6; color:#19180F; font-size:20px; font-family:Arial; padding:10px; border: 5px solid #19180F; border-radius:10px\"> \nðŸ“Œ 1. TFIDF + Stacking + K Fold CV + Optuna based approach <br>\nðŸ“Œ 2. Word2Vec  + Stacking + K Fold CV + Optuna based approach<br>\nðŸ“Œ 3. DistilBERT in PyTorch <br>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color:#A8B4F6; color:#19180F; font-size:20px; font-family:Arial; padding:10px; border: 5px solid #19180F; border-radius:10px\"> \nðŸ“Œ 1. TFIDF + Stacking + K Fold CV + Optuna based approach <br>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\n    Importing modules\n    </div>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier, StackingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nimport optuna","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\n    Loading data.\n    </div>","metadata":{}},{"cell_type":"code","source":"train_essays = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/train_essays.csv', low_memory=True, nrows=2000)\ntest_essays = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/test_essays.csv',nrows=2000)#remove nrows arg when using first method to generate submission\ntrain_prompts = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/train_prompts.csv',nrows=2000)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\n    Merging train essays and train prompts\n    </div>","metadata":{}},{"cell_type":"code","source":"train_data = pd.merge(train_essays, train_prompts, on='prompt_id', how='left')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\n    Splitting the data into training and validation sets\n    </div>","metadata":{}},{"cell_type":"code","source":"train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nFeature engineering using TF-IDF    </div>","metadata":{}},{"cell_type":"code","source":"tfidf_vectorizer = TfidfVectorizer(max_features=5000)\nX_train_tfidf = tfidf_vectorizer.fit_transform(train_data['text'])\nX_val_tfidf = tfidf_vectorizer.transform(val_data['text'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nDefining optuna based hyperparam optimization for random forest    </div>","metadata":{}},{"cell_type":"code","source":"def objective_rf(trial):\n    params = { #define more dense param search space if using this method for submission\n        'n_estimators': trial.suggest_int('n_estimators', 50, 51),\n        'max_depth': trial.suggest_int('max_depth', 5, 6),\n        'min_samples_split': trial.suggest_int('min_samples_split', 2, 3),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 2),\n        'max_features': trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2']),\n    }\n\n    model = RandomForestClassifier(**params, random_state=42)\n    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    score = cross_val_score(model, X_train_tfidf, train_data['generated'], cv=kfold, scoring='accuracy').mean()\n\n    return score\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nDefining optuna based hyperparam optimization for gradient boosting    </div>","metadata":{}},{"cell_type":"code","source":"def objective_gb(trial):\n    params = {#define more dense param search space if using this method for submission\n        'n_estimators': trial.suggest_int('n_estimators', 50, 51),\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.02),\n        'max_depth': trial.suggest_int('max_depth', 3, 4),\n        'subsample': trial.suggest_float('subsample', 0.5, 0.6),\n    }\n\n    model = GradientBoostingClassifier(**params, random_state=42)\n    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    score = cross_val_score(model, X_train_tfidf, train_data['generated'], cv=kfold, scoring='accuracy').mean()\n\n    return score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nDefining optuna based hyperparam optimization for extra trees   </div>","metadata":{}},{"cell_type":"code","source":"def objective_et(trial):\n    params = {#define more dense param search space if using this method for submission\n        'n_estimators': trial.suggest_int('n_estimators', 50, 51),\n        'max_depth': trial.suggest_int('max_depth', 5, 6),\n        'min_samples_split': trial.suggest_int('min_samples_split', 2, 3),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 2),\n        'max_features': trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2']),\n    }\n\n    model = ExtraTreesClassifier(**params, random_state=42)\n    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    score = cross_val_score(model, X_train_tfidf, train_data['generated'], cv=kfold, scoring='accuracy').mean()\n\n    return score\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nDefining and training base mdels    </div>","metadata":{}},{"cell_type":"code","source":"study_rf = optuna.create_study(direction='maximize')\nstudy_rf.optimize(objective_rf, n_trials=1)\n\nstudy_gb = optuna.create_study(direction='maximize')\nstudy_gb.optimize(objective_gb, n_trials=1)\n\nstudy_et = optuna.create_study(direction='maximize')\nstudy_et.optimize(objective_et, n_trials=1)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nFetching the best hyperparameters</div>","metadata":{}},{"cell_type":"code","source":"best_params_rf = study_rf.best_params\nbest_params_gb = study_gb.best_params\nbest_params_et = study_et.best_params\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nTraining base models on best params   </div>","metadata":{}},{"cell_type":"code","source":"best_rf_clf = RandomForestClassifier(**best_params_rf, random_state=42)\nbest_gb_clf = GradientBoostingClassifier(**best_params_gb, random_state=42)\nbest_et_clf = ExtraTreesClassifier(**best_params_et, random_state=42)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nCreating voting classifier with soft voting    </div>","metadata":{}},{"cell_type":"code","source":"soft_voting_clf = VotingClassifier(\n    estimators=[\n        ('rf', best_rf_clf),\n        ('gb', best_gb_clf),\n        ('et', best_et_clf),\n    ],\n    voting='soft'\n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nCreating stacking classifier with logistic regression as meta classifier   </div>","metadata":{}},{"cell_type":"code","source":"stacking_clf = StackingClassifier(\n    estimators=[('rf', best_rf_clf), ('gb', best_gb_clf), ('et', best_et_clf)],\n    final_estimator=LogisticRegression(),\n    stack_method='auto', \n    n_jobs=-1, \n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nTraining soft voting and stacking classifier    </div>","metadata":{}},{"cell_type":"code","source":"soft_voting_clf.fit(X_train_tfidf, train_data['generated'])\nstacking_clf.fit(X_train_tfidf, train_data['generated'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nMaking predictions on the val set for soft voting</div>","metadata":{}},{"cell_type":"code","source":"val_predictions_soft = soft_voting_clf.predict(X_val_tfidf)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nEvaluating soft voting model    </div>","metadata":{}},{"cell_type":"code","source":"accuracy_soft = accuracy_score(val_data['generated'], val_predictions_soft)\nprint(f'Soft Voting Model Accuracy: {accuracy_soft:.2f}')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nMaking predictions on the val set for stacking model   </div>","metadata":{}},{"cell_type":"code","source":"val_predictions_stacking = stacking_clf.predict(X_val_tfidf)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nEvaluating stacking model    </div>","metadata":{}},{"cell_type":"code","source":"accuracy_stacking = accuracy_score(val_data['generated'], val_predictions_stacking)\nprint(f'Stacking Model Accuracy: {accuracy_stacking:.2f}')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nMaking predictions on the test set for soft voting    </div>","metadata":{}},{"cell_type":"code","source":"X_test_tfidf = tfidf_vectorizer.transform(test_essays['text'])\ntest_predictions_soft = soft_voting_clf.predict_proba(X_test_tfidf)[:, 1]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nCreating submission file for soft voting   </div>","metadata":{}},{"cell_type":"code","source":"submission_df_soft = pd.DataFrame({'id': test_essays['id'], 'generated': test_predictions_soft})\nsubmission_df_soft.to_csv('submission_soft_voting.csv', index=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nMaking preds on test set for stacking and generating submission file    </div>","metadata":{}},{"cell_type":"code","source":"test_predictions_stacking = stacking_clf.predict_proba(X_test_tfidf)[:, 1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df_stacking = pd.DataFrame({'id': test_essays['id'], 'generated': test_predictions_stacking})\nsubmission_df_stacking.to_csv('submission.csv', index=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df_soft","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df_stacking\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#A8B4F6; color:#19180F; font-size:20px; font-family:Arial; padding:10px; border: 5px solid #19180F; border-radius:10px\"> \nðŸ“Œ 2. Word2vec + Stacking + KfoldCV + Optuna <br>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nImporting modules   </div>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier, StackingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nimport optuna\nfrom gensim.models import KeyedVectors\nfrom sklearn.preprocessing import LabelEncoder\n","metadata":{"execution":{"iopub.status.busy":"2023-12-16T13:11:19.628292Z","iopub.execute_input":"2023-12-16T13:11:19.628946Z","iopub.status.idle":"2023-12-16T13:11:30.383035Z","shell.execute_reply.started":"2023-12-16T13:11:19.628900Z","shell.execute_reply":"2023-12-16T13:11:30.382086Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nLoading word2vec model   </div>","metadata":{}},{"cell_type":"code","source":"word2vec_model = KeyedVectors.load_word2vec_format('/kaggle/input/google-word2vec/GoogleNews-vectors-negative300.bin', binary=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-16T13:11:30.384889Z","iopub.execute_input":"2023-12-16T13:11:30.385813Z","iopub.status.idle":"2023-12-16T13:12:40.868818Z","shell.execute_reply.started":"2023-12-16T13:11:30.385778Z","shell.execute_reply":"2023-12-16T13:12:40.868079Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nLoading data  </div>","metadata":{}},{"cell_type":"code","source":"train_essays = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/train_essays.csv', low_memory=True,nrows=4000)\ntest_essays = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/test_essays.csv',nrows=4000)\ntrain_prompts = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/train_prompts.csv',nrows=4000)#remove nrows arg if you want to submit via this\n\ntrain_data = pd.merge(train_essays, train_prompts, on='prompt_id', how='left')\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-16T13:12:40.911663Z","iopub.execute_input":"2023-12-16T13:12:40.912071Z","iopub.status.idle":"2023-12-16T13:12:41.049521Z","shell.execute_reply.started":"2023-12-16T13:12:40.912045Z","shell.execute_reply":"2023-12-16T13:12:41.048592Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nEncoding labels\n</div>","metadata":{}},{"cell_type":"code","source":"label_encoder = LabelEncoder()\ntrain_data['generated'] = label_encoder.fit_transform(train_data['generated'])\n#train_data['generated'] = [0,1,0,1,0,0,0,0,0,1] #for sanity check of code","metadata":{"execution":{"iopub.status.busy":"2023-12-16T13:12:41.051705Z","iopub.execute_input":"2023-12-16T13:12:41.052014Z","iopub.status.idle":"2023-12-16T13:12:41.060009Z","shell.execute_reply.started":"2023-12-16T13:12:41.051989Z","shell.execute_reply":"2023-12-16T13:12:41.058967Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n","output_type":"stream"}]},{"cell_type":"code","source":"np.unique(train_data['generated'].values)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-16T13:12:41.061331Z","iopub.execute_input":"2023-12-16T13:12:41.061588Z","iopub.status.idle":"2023-12-16T13:12:41.071109Z","shell.execute_reply.started":"2023-12-16T13:12:41.061566Z","shell.execute_reply":"2023-12-16T13:12:41.070300Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"array([0, 1])"},"metadata":{}}]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nSplitting the data   </div>","metadata":{}},{"cell_type":"code","source":"train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T13:12:41.072038Z","iopub.execute_input":"2023-12-16T13:12:41.072268Z","iopub.status.idle":"2023-12-16T13:12:41.084188Z","shell.execute_reply.started":"2023-12-16T13:12:41.072248Z","shell.execute_reply":"2023-12-16T13:12:41.083240Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nTokenizing and padding sequences   </div>","metadata":{}},{"cell_type":"code","source":"X_train_word2vec = train_data['text'].apply(lambda x: [word2vec_model[word] for word in x.split() if word in word2vec_model]).values.tolist()\nX_val_word2vec = val_data['text'].apply(lambda x: [word2vec_model[word] for word in x.split() if word in word2vec_model]).values.tolist()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-16T13:12:41.085309Z","iopub.execute_input":"2023-12-16T13:12:41.085564Z","iopub.status.idle":"2023-12-16T13:12:42.932742Z","shell.execute_reply.started":"2023-12-16T13:12:41.085542Z","shell.execute_reply":"2023-12-16T13:12:42.931748Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nDefining objective functions for hyperparam tuning   </div>","metadata":{}},{"cell_type":"code","source":"def objective_rf(trial):\n    params = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 51),\n        'max_depth': trial.suggest_int('max_depth', 5, 6),\n        'min_samples_split': trial.suggest_int('min_samples_split', 2, 3),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 2),\n        'max_features': trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2']),\n    }\n\n    model = RandomForestClassifier(**params, random_state=42)\n\n    max_seq_length = max(len(seq) for seq in X_train_word2vec)\n    X_train_padded = np.array([np.pad(seq, ((0, max_seq_length - len(seq)), (0, 0)), mode='constant') for seq in X_train_word2vec])\n\n    X_train_padded = X_train_padded.reshape((X_train_padded.shape[0], -1))\n\n    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    score = cross_val_score(model, X_train_padded, train_data['generated'], cv=kfold, scoring='accuracy').mean()\n\n    return score\n\n\ndef objective_gb(trial):\n    params = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 51),\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.02),\n        'max_depth': trial.suggest_int('max_depth', 3, 4),\n        'subsample': trial.suggest_float('subsample', 0.5, 0.6),\n    }\n\n    model = GradientBoostingClassifier(**params, random_state=42)\n\n    max_seq_length = max(len(seq) for seq in X_train_word2vec)\n    X_train_padded = np.array([np.pad(seq, ((0, max_seq_length - len(seq)), (0, 0)), mode='constant') for seq in X_train_word2vec])\n    X_train_padded = X_train_padded.reshape((X_train_padded.shape[0], -1))\n\n    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    score = cross_val_score(model, X_train_padded, train_data['generated'], cv=kfold, scoring='accuracy').mean()\n\n    return score\n\ndef objective_et(trial):\n    params = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 51),\n        'max_depth': trial.suggest_int('max_depth', 5, 6),\n        'min_samples_split': trial.suggest_int('min_samples_split', 2, 3),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 2),\n        'max_features': trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2']),\n    }\n\n    model = ExtraTreesClassifier(**params, random_state=42)\n\n    max_seq_length = max(len(seq) for seq in X_train_word2vec)\n    X_train_padded = np.array([np.pad(seq, ((0, max_seq_length - len(seq)), (0, 0)), mode='constant') for seq in X_train_word2vec])\n    X_train_padded = X_train_padded.reshape((X_train_padded.shape[0], -1))\n\n    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    score = cross_val_score(model, X_train_padded, train_data['generated'], cv=kfold, scoring='accuracy').mean()\n\n    return score\n","metadata":{"execution":{"iopub.status.busy":"2023-12-16T13:12:43.111999Z","iopub.execute_input":"2023-12-16T13:12:43.112255Z","iopub.status.idle":"2023-12-16T13:12:43.128687Z","shell.execute_reply.started":"2023-12-16T13:12:43.112231Z","shell.execute_reply":"2023-12-16T13:12:43.127689Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nOptimizing hyperparams  </div>","metadata":{}},{"cell_type":"code","source":"#uncomment if you're submitting via this\n# study_rf = optuna.create_study(direction='maximize')\n# study_rf.optimize(objective_rf, n_trials=1)#increase num trials if you want to do more extensive search\n\n# study_gb = optuna.create_study(direction='maximize')\n# study_gb.optimize(objective_gb, n_trials=1)\n\n# study_et = optuna.create_study(direction='maximize')\n# study_et.optimize(objective_et, n_trials=1)\n","metadata":{"_kg_hide-output":true,"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-12-16T13:30:31.436868Z","iopub.execute_input":"2023-12-16T13:30:31.437255Z","iopub.status.idle":"2023-12-16T13:30:31.441956Z","shell.execute_reply.started":"2023-12-16T13:30:31.437225Z","shell.execute_reply":"2023-12-16T13:30:31.441019Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nFetching the best params   </div>","metadata":{}},{"cell_type":"code","source":"# best_params_rf = study_rf.best_params\n# best_params_gb = study_gb.best_params\n# best_params_et = study_et.best_params\n#uncomment if you ran optuna and wish to submit via this","metadata":{"execution":{"iopub.status.busy":"2023-12-16T13:30:49.952406Z","iopub.execute_input":"2023-12-16T13:30:49.952812Z","iopub.status.idle":"2023-12-16T13:30:49.957233Z","shell.execute_reply.started":"2023-12-16T13:30:49.952781Z","shell.execute_reply":"2023-12-16T13:30:49.956272Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nInitializing the models with best params   </div>","metadata":{}},{"cell_type":"code","source":"#uncomment if you ran optuna previously\nbest_params_rf = {\n    'n_estimators': 100,\n    'max_depth': 10,\n    'min_samples_split': 5,\n    'min_samples_leaf': 2,\n    'max_features': 'sqrt',\n}\n\nbest_params_gb = {\n    'n_estimators': 150,\n    'learning_rate': 0.1,\n    'max_depth': 5,\n    'subsample': 0.8,\n}\n\nbest_params_et = {\n    'n_estimators': 120,\n    'max_depth': 15,\n    'min_samples_split': 10,\n    'min_samples_leaf': 3,\n    'max_features': 'log2',\n}\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-12-16T13:32:13.309219Z","iopub.execute_input":"2023-12-16T13:32:13.310189Z","iopub.status.idle":"2023-12-16T13:32:13.316599Z","shell.execute_reply.started":"2023-12-16T13:32:13.310149Z","shell.execute_reply":"2023-12-16T13:32:13.315604Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"best_rf_clf = RandomForestClassifier(**best_params_rf, random_state=42)\nbest_gb_clf = GradientBoostingClassifier(**best_params_gb, random_state=42)\nbest_et_clf = ExtraTreesClassifier(**best_params_et, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-16T13:32:14.776220Z","iopub.execute_input":"2023-12-16T13:32:14.776587Z","iopub.status.idle":"2023-12-16T13:32:14.781786Z","shell.execute_reply.started":"2023-12-16T13:32:14.776557Z","shell.execute_reply":"2023-12-16T13:32:14.780860Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nInstantiating soft voting and stacking classifier   </div>","metadata":{}},{"cell_type":"code","source":"soft_voting_clf = VotingClassifier(\n    estimators=[\n        ('rf', best_rf_clf),\n        ('gb', best_gb_clf),\n        ('et', best_et_clf),\n    ],\n    voting='soft'\n)\n\nstacking_clf = StackingClassifier(\n    estimators=[('rf', best_rf_clf), ('gb', best_gb_clf), ('et', best_et_clf)],\n    final_estimator=LogisticRegression(),\n    stack_method='auto', \n    n_jobs=-1, \n)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-16T13:32:16.093346Z","iopub.execute_input":"2023-12-16T13:32:16.094335Z","iopub.status.idle":"2023-12-16T13:32:16.099467Z","shell.execute_reply.started":"2023-12-16T13:32:16.094300Z","shell.execute_reply":"2023-12-16T13:32:16.098597Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nPadding sequences to common length and evaluating after fitting   </div>","metadata":{}},{"cell_type":"code","source":"max_seq_length_train = max(len(seq) for seq in X_train_word2vec)\nmax_seq_length_val = max(len(seq) for seq in X_val_word2vec)\nmax_seq_length = max(max_seq_length_train, max_seq_length_val)\n\nX_train_padded = np.array([np.pad(seq, ((0, max_seq_length - len(seq)), (0, 0)), mode='constant') for seq in X_train_word2vec])\nX_train_padded = X_train_padded.reshape((X_train_padded.shape[0], -1))\n\nX_val_padded = np.array([np.pad(seq, ((0, max_seq_length - len(seq)), (0, 0)), mode='constant') for seq in X_val_word2vec])\nX_val_padded = X_val_padded.reshape((X_val_padded.shape[0], -1))\n\nsoft_voting_clf.fit(X_train_padded, train_data['generated'])\nstacking_clf.fit(X_train_padded, train_data['generated'])\n\nval_predictions_soft = soft_voting_clf.predict(X_val_padded)\naccuracy_soft = accuracy_score(val_data['generated'], val_predictions_soft)\nprint(f'Soft Voting Model Accuracy: {accuracy_soft:.2f}')\n\nval_predictions_stacking = stacking_clf.predict(X_val_padded)\naccuracy_stacking = accuracy_score(val_data['generated'], val_predictions_stacking)\nprint(f'Stacking Model Accuracy: {accuracy_stacking:.2f}')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-16T13:32:17.175372Z","iopub.execute_input":"2023-12-16T13:32:17.176352Z","iopub.status.idle":"2023-12-16T13:43:09.268723Z","shell.execute_reply.started":"2023-12-16T13:32:17.176317Z","shell.execute_reply":"2023-12-16T13:43:09.266241Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m X_val_padded \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39mpad(seq, ((\u001b[38;5;241m0\u001b[39m, max_seq_length \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(seq)), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m X_val_word2vec])\n\u001b[1;32m      9\u001b[0m X_val_padded \u001b[38;5;241m=\u001b[39m X_val_padded\u001b[38;5;241m.\u001b[39mreshape((X_val_padded\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 11\u001b[0m \u001b[43msoft_voting_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgenerated\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m stacking_clf\u001b[38;5;241m.\u001b[39mfit(X_train_padded, train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     14\u001b[0m val_predictions_soft \u001b[38;5;241m=\u001b[39m soft_voting_clf\u001b[38;5;241m.\u001b[39mpredict(X_val_padded)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_voting.py:346\u001b[0m, in \u001b[0;36mVotingClassifier.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mle_\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m    344\u001b[0m transformed_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mle_\u001b[38;5;241m.\u001b[39mtransform(y)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformed_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_voting.py:81\u001b[0m, in \u001b[0;36m_BaseVoting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of `estimators` and weights must be equal; got\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m weights, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m     )\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_single_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mVoting\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclfs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclfs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdrop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     92\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamed_estimators_ \u001b[38;5;241m=\u001b[39m Bunch()\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Uses 'drop' as placeholder for dropped estimators\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_base.py:46\u001b[0m, in \u001b[0;36m_fit_single_estimator\u001b[0;34m(estimator, X, y, sample_weight, message_clsname, message)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m---> 46\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:538\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[1;32m    537\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:615\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    608\u001b[0m     old_oob_score \u001b[38;5;241m=\u001b[39m loss_(\n\u001b[1;32m    609\u001b[0m         y[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[1;32m    610\u001b[0m         raw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[1;32m    611\u001b[0m         sample_weight[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[1;32m    612\u001b[0m     )\n\u001b[1;32m    614\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[0;32m--> 615\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;66;03m# track deviance (= loss)\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:257\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    254\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m    256\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[0;32m--> 257\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[1;32m    260\u001b[0m loss\u001b[38;5;241m.\u001b[39mupdate_terminal_regions(\n\u001b[1;32m    261\u001b[0m     tree\u001b[38;5;241m.\u001b[39mtree_,\n\u001b[1;32m    262\u001b[0m     X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m     k\u001b[38;5;241m=\u001b[39mk,\n\u001b[1;32m    270\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/tree/_classes.py:1247\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m \n\u001b[1;32m   1221\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1247\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/tree/_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    370\u001b[0m         splitter,\n\u001b[1;32m    371\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    377\u001b[0m     )\n\u001b[0;32m--> 379\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nGenerating submission by predicting on test set   </div>","metadata":{}},{"cell_type":"code","source":"X_test_word2vec = test_essays['text'].apply(lambda x: [word2vec_model[word] for word in x.split() if word in word2vec_model]).values.tolist()\n\nmax_seq_length_test = max(len(seq) for seq in X_test_word2vec)\n\nX_test_padded = np.array([\n    np.pad(seq, ((0, max_seq_length_test - len(seq)), (0, 0)), mode='constant') for seq in X_test_word2vec\n])\nX_test_padded = X_test_padded.reshape((X_test_padded.shape[0], -1))\n\nmax_features_train = X_train_padded.shape[1]\nif X_test_padded.shape[1] < max_features_train:\n    X_test_padded = np.pad(X_test_padded, ((0, 0), (0, max_features_train - X_test_padded.shape[1])), mode='constant')\nelif X_test_padded.shape[1] > max_features_train:\n    X_test_padded = X_test_padded[:, :max_features_train]\n\ntest_predictions_soft = soft_voting_clf.predict_proba(X_test_padded)\n\nsubmission_df_soft = pd.DataFrame({'id': test_essays['id'], 'generated': test_predictions_soft[:, 1]})\n\nsubmission_df_soft.to_csv('submission.csv', index=False)\n\ntest_predictions_stacking = stacking_clf.predict_proba(X_test_padded)\n\nsubmission_df_stacking = pd.DataFrame({'id': test_essays['id'], 'generated': test_predictions_stacking[:, 1]})\nsubmission_df_stacking.to_csv('submission_stacking.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-16T13:43:09.269388Z","iopub.status.idle":"2023-12-16T13:43:09.269708Z","shell.execute_reply.started":"2023-12-16T13:43:09.269553Z","shell.execute_reply":"2023-12-16T13:43:09.269567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df_stacking","metadata":{"execution":{"iopub.status.busy":"2023-12-16T13:43:09.271348Z","iopub.status.idle":"2023-12-16T13:43:09.271829Z","shell.execute_reply.started":"2023-12-16T13:43:09.271592Z","shell.execute_reply":"2023-12-16T13:43:09.271615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df_soft","metadata":{"execution":{"iopub.status.busy":"2023-12-16T13:43:09.273567Z","iopub.status.idle":"2023-12-16T13:43:09.274089Z","shell.execute_reply.started":"2023-12-16T13:43:09.273805Z","shell.execute_reply":"2023-12-16T13:43:09.273826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#A8B4F6; color:#19180F; font-size:20px; font-family:Arial; padding:10px; border: 5px solid #19180F; border-radius:10px\"> \nðŸ“Œ 3. DistilBERT in PyTorch <br>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nImporting modules   </div>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom tqdm import tqdm\n","metadata":{"execution":{"iopub.status.busy":"2023-12-16T13:44:00.286155Z","iopub.execute_input":"2023-12-16T13:44:00.286898Z","iopub.status.idle":"2023-12-16T13:44:04.028684Z","shell.execute_reply.started":"2023-12-16T13:44:00.286868Z","shell.execute_reply":"2023-12-16T13:44:04.027820Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nLoading data   </div>","metadata":{}},{"cell_type":"code","source":"train_essays = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/train_essays.csv', low_memory=True)\ntest_essays = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/test_essays.csv')\ntrain_prompts = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/train_prompts.csv')\ntrain_data = pd.merge(train_essays, train_prompts, on='prompt_id', how='left')","metadata":{"execution":{"iopub.status.busy":"2023-12-16T13:44:04.030312Z","iopub.execute_input":"2023-12-16T13:44:04.030835Z","iopub.status.idle":"2023-12-16T13:44:04.082866Z","shell.execute_reply.started":"2023-12-16T13:44:04.030808Z","shell.execute_reply":"2023-12-16T13:44:04.081895Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nDefining the dataset class </div>","metadata":{}},{"cell_type":"code","source":"class EssaysDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length=256):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        label = int(self.labels[idx])\n        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n\n        return {\n            'input_ids': encoding['input_ids'].squeeze(),\n            'attention_mask': encoding['attention_mask'].squeeze(),\n            'label': torch.tensor(label, dtype=torch.float32)\n        }\n","metadata":{"execution":{"iopub.status.busy":"2023-12-16T13:44:04.084121Z","iopub.execute_input":"2023-12-16T13:44:04.084414Z","iopub.status.idle":"2023-12-16T13:44:04.092236Z","shell.execute_reply.started":"2023-12-16T13:44:04.084390Z","shell.execute_reply":"2023-12-16T13:44:04.091256Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model_tokenizer_dir= '/kaggle/input/distilbert-model-num-labels-1'\nmodel = DistilBertForSequenceClassification.from_pretrained(model_tokenizer_dir)\ntokenizer = DistilBertTokenizer.from_pretrained(model_tokenizer_dir)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T13:44:30.378904Z","iopub.execute_input":"2023-12-16T13:44:30.379843Z","iopub.status.idle":"2023-12-16T13:44:31.086537Z","shell.execute_reply.started":"2023-12-16T13:44:30.379809Z","shell.execute_reply":"2023-12-16T13:44:31.085556Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nSplitting the data into train and val sets   </div>","metadata":{}},{"cell_type":"code","source":"train_texts, val_texts, train_labels, val_labels = train_test_split(\n    train_data['text'].values,\n    train_data['generated'].values,\n    test_size=0.2,\n    random_state=42\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T13:44:32.387993Z","iopub.execute_input":"2023-12-16T13:44:32.388741Z","iopub.status.idle":"2023-12-16T13:44:32.395145Z","shell.execute_reply.started":"2023-12-16T13:44:32.388711Z","shell.execute_reply":"2023-12-16T13:44:32.393941Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nCreating datasets and dataloaders  </div>","metadata":{}},{"cell_type":"code","source":"train_dataset = EssaysDataset(train_texts, train_labels, tokenizer)\nval_dataset = EssaysDataset(val_texts, val_labels, tokenizer)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-16T13:44:33.337850Z","iopub.execute_input":"2023-12-16T13:44:33.338240Z","iopub.status.idle":"2023-12-16T13:44:33.343928Z","shell.execute_reply.started":"2023-12-16T13:44:33.338212Z","shell.execute_reply":"2023-12-16T13:44:33.342931Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nHyperparams  </div>","metadata":{}},{"cell_type":"code","source":"epochs = 10\nlr = 2e-5\n\noptimizer = AdamW(model.parameters(), lr=lr)\ncriterion = torch.nn.BCEWithLogitsLoss()\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T13:44:33.793977Z","iopub.execute_input":"2023-12-16T13:44:33.794628Z","iopub.status.idle":"2023-12-16T13:44:36.890688Z","shell.execute_reply.started":"2023-12-16T13:44:33.794599Z","shell.execute_reply":"2023-12-16T13:44:36.889706Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nTraining loop </div>","metadata":{}},{"cell_type":"code","source":"for epoch in tqdm(range(epochs)):\n    model.train()\n    for step,batch in (enumerate(train_dataloader)):\n        optimizer.zero_grad()\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n        outputs = model(input_ids, attention_mask=attention_mask)\n        loss = criterion(outputs.logits.squeeze(), labels)\n        if step%100==0:\n            print(\"Step-{}, Loss-{}\".format(step,loss.item()))\n        loss.backward()\n        optimizer.step()\n\n    model.eval()\n    all_val_labels = []\n    all_val_preds = []\n    with torch.no_grad():\n        for batch in val_dataloader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n            outputs = model(input_ids, attention_mask=attention_mask)\n            val_preds = torch.sigmoid(outputs.logits.squeeze()).detach().cpu().numpy()\n            all_val_labels.extend(labels.cpu().numpy())\n            all_val_preds.extend(val_preds)\n\n    auc_roc = roc_auc_score(all_val_labels, all_val_preds)\n    print(f'Epoch {epoch + 1}/{epochs}, AUC-ROC: {auc_roc}')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-16T13:44:36.892521Z","iopub.execute_input":"2023-12-16T13:44:36.893371Z","iopub.status.idle":"2023-12-16T13:44:43.935030Z","shell.execute_reply.started":"2023-12-16T13:44:36.893336Z","shell.execute_reply":"2023-12-16T13:44:43.933481Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"  0%|          | 0/10 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Step-0, Loss-0.0033012470230460167\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/10 [00:06<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[24], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep-\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, Loss-\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(step,loss\u001b[38;5;241m.\u001b[39mitem()))\n\u001b[1;32m     12\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 13\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     16\u001b[0m all_val_labels \u001b[38;5;241m=\u001b[39m []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:468\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    466\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mmul_(beta1)\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m beta1))\n\u001b[1;32m    467\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[0;32m--> 468\u001b[0m denom \u001b[38;5;241m=\u001b[39m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39madd_(group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    470\u001b[0m step_size \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorrect_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m]:  \u001b[38;5;66;03m# No bias correction for Bert\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"<div style=\"background-color:#F0E3D2; color:#19180F; font-size:15px; font-family:Verdana; padding:10px; border: 2px solid #19180F; border-radius:10px\"> \nðŸ“Œ\nGenerating submission  </div>","metadata":{}},{"cell_type":"code","source":"test_dataset = EssaysDataset(test_essays['text'].values, [0] * len(test_essays), tokenizer)\ntest_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n\nmodel.eval()\nall_test_preds = []\nwith torch.no_grad():\n    for batch in test_dataloader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        outputs = model(input_ids, attention_mask=attention_mask)\n        test_preds = torch.sigmoid(outputs.logits.squeeze()).detach().cpu().numpy()\n        all_test_preds.extend(test_preds)\n\nsubmission_df = pd.DataFrame({'id': test_essays['id'], 'generated': all_test_preds})\nsubmission_df.to_csv('submission.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-16T13:44:49.727788Z","iopub.execute_input":"2023-12-16T13:44:49.728579Z","iopub.status.idle":"2023-12-16T13:44:49.758091Z","shell.execute_reply.started":"2023-12-16T13:44:49.728546Z","shell.execute_reply":"2023-12-16T13:44:49.757301Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"submission_df","metadata":{"execution":{"iopub.status.busy":"2023-12-16T13:44:50.049649Z","iopub.execute_input":"2023-12-16T13:44:50.050540Z","iopub.status.idle":"2023-12-16T13:44:50.062574Z","shell.execute_reply.started":"2023-12-16T13:44:50.050508Z","shell.execute_reply":"2023-12-16T13:44:50.061640Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"         id  generated\n0  0000aaaa   0.021260\n1  1111bbbb   0.028847\n2  2222cccc   0.024098","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000aaaa</td>\n      <td>0.021260</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1111bbbb</td>\n      <td>0.028847</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2222cccc</td>\n      <td>0.024098</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# output_dir = '/kaggle/working/'\n# tokenizer.save_pretrained(output_dir)\n# model.save_pretrained(output_dir)","metadata":{"execution":{"iopub.status.busy":"2023-12-16T13:44:07.239296Z","iopub.status.idle":"2023-12-16T13:44:07.239607Z","shell.execute_reply.started":"2023-12-16T13:44:07.239451Z","shell.execute_reply":"2023-12-16T13:44:07.239465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}