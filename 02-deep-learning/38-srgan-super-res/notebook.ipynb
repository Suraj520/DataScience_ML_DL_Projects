{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T7YNT_eiV6M"
      },
      "source": [
        "#### About\n",
        "Image super resolution using SRGAN.\n",
        "> Concepts\n",
        "1. SRGAN replaces the MSE Loss(Euclidean distance based Pixel loss) by Perceptual loss along with maximising the peak signal to noise ratio.\n",
        "2. Perceptual loss is a combination of both adversarial loss(discriminator loss) and content loss(generator loss).\n",
        "3. Content loss(generator loss) helps in enhancing the perceptual similarity rather than seeking improvement in pixel space. Structural information. It is also defined as VGG Loss. We compare high level features in the generated image and ground truth image. These high level features are feature maps from pre-trained VGG Net model.\n",
        "4. SR Gan usually uses the upsampling factor of 4 as per research paper. We will experiment with 8.\n",
        "5. SRGAN needs dataset in pair of High resolution and Low resolution images. Usually, We collect HQ images and then downsample it to generate using LQ images by adding noise, blurring etc. We will use Div2K dataset\n",
        "6. Generator model takes in LQ images and generates HQ images. Discriminator is trained to differentiate between real HQ image and generated HQ image. It will then update weights of discriminator and generator accordingly.\n",
        "7. Once training is done, We only need generator. Discriminator is used for training. Generator takes in LQ images at run time and generate HQ images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJ47AThwiNhl",
        "outputId": "b6883a7b-f0e8-4b63-de1c-0aa8fa73600e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-03-15 14:50:54--  http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_HR.zip\n",
            "Resolving data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)... 129.132.52.178, 2001:67c:10ec:36c2::178\n",
            "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.178|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_HR.zip [following]\n",
            "--2023-03-15 14:50:54--  https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_HR.zip\n",
            "Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.178|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 448993893 (428M) [application/zip]\n",
            "Saving to: ‘DIV2K_valid_HR.zip’\n",
            "\n",
            "DIV2K_valid_HR.zip  100%[===================>] 428.19M  18.0MB/s    in 23s     \n",
            "\n",
            "2023-03-15 14:51:18 (18.5 MB/s) - ‘DIV2K_valid_HR.zip’ saved [448993893/448993893]\n",
            "\n",
            "Archive:  DIV2K_valid_HR.zip\n",
            "   creating: DIV2K_valid_HR/\n",
            "  inflating: DIV2K_valid_HR/0897.png  \n",
            "  inflating: DIV2K_valid_HR/0887.png  \n",
            "  inflating: DIV2K_valid_HR/0806.png  \n",
            "  inflating: DIV2K_valid_HR/0834.png  \n",
            "  inflating: DIV2K_valid_HR/0896.png  \n",
            "  inflating: DIV2K_valid_HR/0881.png  \n",
            "  inflating: DIV2K_valid_HR/0828.png  \n",
            "  inflating: DIV2K_valid_HR/0833.png  \n",
            "  inflating: DIV2K_valid_HR/0877.png  \n",
            "  inflating: DIV2K_valid_HR/0826.png  \n",
            "  inflating: DIV2K_valid_HR/0879.png  \n",
            "  inflating: DIV2K_valid_HR/0812.png  \n",
            "  inflating: DIV2K_valid_HR/0809.png  \n",
            "  inflating: DIV2K_valid_HR/0865.png  \n",
            "  inflating: DIV2K_valid_HR/0882.png  \n",
            "  inflating: DIV2K_valid_HR/0830.png  \n",
            "  inflating: DIV2K_valid_HR/0892.png  \n",
            "  inflating: DIV2K_valid_HR/0859.png  \n",
            "  inflating: DIV2K_valid_HR/0858.png  \n",
            "  inflating: DIV2K_valid_HR/0816.png  \n",
            "  inflating: DIV2K_valid_HR/0836.png  \n",
            "  inflating: DIV2K_valid_HR/0857.png  \n",
            "  inflating: DIV2K_valid_HR/0824.png  \n",
            "  inflating: DIV2K_valid_HR/0823.png  \n",
            "  inflating: DIV2K_valid_HR/0810.png  \n",
            "  inflating: DIV2K_valid_HR/0900.png  \n",
            "  inflating: DIV2K_valid_HR/0884.png  \n",
            "  inflating: DIV2K_valid_HR/0890.png  \n",
            "  inflating: DIV2K_valid_HR/0835.png  \n",
            "  inflating: DIV2K_valid_HR/0848.png  \n",
            "  inflating: DIV2K_valid_HR/0869.png  \n",
            "  inflating: DIV2K_valid_HR/0878.png  \n",
            "  inflating: DIV2K_valid_HR/0860.png  \n",
            "  inflating: DIV2K_valid_HR/0851.png  \n",
            "  inflating: DIV2K_valid_HR/0870.png  \n",
            "  inflating: DIV2K_valid_HR/0867.png  \n",
            "  inflating: DIV2K_valid_HR/0898.png  \n",
            "  inflating: DIV2K_valid_HR/0818.png  \n",
            "  inflating: DIV2K_valid_HR/0814.png  \n",
            "  inflating: DIV2K_valid_HR/0895.png  \n",
            "  inflating: DIV2K_valid_HR/0856.png  \n",
            "  inflating: DIV2K_valid_HR/0891.png  \n",
            "  inflating: DIV2K_valid_HR/0829.png  \n",
            "  inflating: DIV2K_valid_HR/0825.png  \n",
            "  inflating: DIV2K_valid_HR/0853.png  \n",
            "  inflating: DIV2K_valid_HR/0894.png  \n",
            "  inflating: DIV2K_valid_HR/0863.png  \n",
            "  inflating: DIV2K_valid_HR/0883.png  \n",
            "  inflating: DIV2K_valid_HR/0822.png  \n",
            "  inflating: DIV2K_valid_HR/0837.png  \n",
            "  inflating: DIV2K_valid_HR/0849.png  \n",
            "  inflating: DIV2K_valid_HR/0899.png  \n",
            "  inflating: DIV2K_valid_HR/0807.png  \n",
            "  inflating: DIV2K_valid_HR/0864.png  \n",
            "  inflating: DIV2K_valid_HR/0845.png  \n",
            "  inflating: DIV2K_valid_HR/0871.png  \n",
            "  inflating: DIV2K_valid_HR/0804.png  \n",
            "  inflating: DIV2K_valid_HR/0815.png  \n",
            "  inflating: DIV2K_valid_HR/0813.png  \n",
            "  inflating: DIV2K_valid_HR/0868.png  \n",
            "  inflating: DIV2K_valid_HR/0893.png  \n",
            "  inflating: DIV2K_valid_HR/0876.png  \n",
            "  inflating: DIV2K_valid_HR/0889.png  \n",
            "  inflating: DIV2K_valid_HR/0843.png  \n",
            "  inflating: DIV2K_valid_HR/0862.png  \n",
            "  inflating: DIV2K_valid_HR/0875.png  \n",
            "  inflating: DIV2K_valid_HR/0885.png  \n",
            "  inflating: DIV2K_valid_HR/0866.png  \n",
            "  inflating: DIV2K_valid_HR/0839.png  \n",
            "  inflating: DIV2K_valid_HR/0873.png  \n",
            "  inflating: DIV2K_valid_HR/0820.png  \n",
            "  inflating: DIV2K_valid_HR/0852.png  \n",
            "  inflating: DIV2K_valid_HR/0819.png  \n",
            "  inflating: DIV2K_valid_HR/0808.png  \n",
            "  inflating: DIV2K_valid_HR/0802.png  \n",
            "  inflating: DIV2K_valid_HR/0821.png  \n",
            "  inflating: DIV2K_valid_HR/0811.png  \n",
            "  inflating: DIV2K_valid_HR/0847.png  \n",
            "  inflating: DIV2K_valid_HR/0838.png  \n",
            "  inflating: DIV2K_valid_HR/0827.png  \n",
            "  inflating: DIV2K_valid_HR/0844.png  \n",
            "  inflating: DIV2K_valid_HR/0872.png  \n",
            "  inflating: DIV2K_valid_HR/0880.png  \n",
            "  inflating: DIV2K_valid_HR/0854.png  \n",
            "  inflating: DIV2K_valid_HR/0831.png  \n",
            "  inflating: DIV2K_valid_HR/0841.png  \n",
            "  inflating: DIV2K_valid_HR/0832.png  \n",
            "  inflating: DIV2K_valid_HR/0801.png  \n",
            "  inflating: DIV2K_valid_HR/0805.png  \n",
            "  inflating: DIV2K_valid_HR/0888.png  \n",
            "  inflating: DIV2K_valid_HR/0861.png  \n",
            "  inflating: DIV2K_valid_HR/0817.png  \n",
            "  inflating: DIV2K_valid_HR/0803.png  \n",
            "  inflating: DIV2K_valid_HR/0842.png  \n",
            "  inflating: DIV2K_valid_HR/0855.png  \n",
            "  inflating: DIV2K_valid_HR/0840.png  \n",
            "  inflating: DIV2K_valid_HR/0874.png  \n",
            "  inflating: DIV2K_valid_HR/0846.png  \n",
            "  inflating: DIV2K_valid_HR/0886.png  \n",
            "  inflating: DIV2K_valid_HR/0850.png  \n"
          ]
        }
      ],
      "source": [
        "# downloading the dataset\n",
        "!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n",
        "!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_HR.zip\n",
        "#unzipping the dataset\n",
        "!unzip DIV2K_train_HR.zip\n",
        "!unzip DIV2K_valid_HR.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dh2D9bvcijPX"
      },
      "outputs": [],
      "source": [
        "#loading modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "import torch.optim as optim\n",
        "from torchvision.models.vgg import vgg16\n",
        "from math import exp\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.utils as utils\n",
        "from torch.autograd import Variable\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import pandas as pd\n",
        "import os\n",
        "from os import listdir\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from os.path import join"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "G7r0DXZ_jEwI"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "GpwM6pLsjKIs"
      },
      "outputs": [],
      "source": [
        "upscale_factor = 8\n",
        "crop_size= 88\n",
        "num_epochs= 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ZG4HZm7NjOfc"
      },
      "outputs": [],
      "source": [
        "mean = np.array([0.485, 0.456, 0.406])\n",
        "std = np.array([0.229, 0.224, 0.225])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "MkcEDm3MjStk"
      },
      "outputs": [],
      "source": [
        "# helper util functions\n",
        "def is_image(filename):\n",
        "  return any(filename.endswith(extension) for extension in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG'])\n",
        "\n",
        "def calc_valid_crop_size(crop_size,upscale_factor):\n",
        "  return crop_size - (crop_size % upscale_factor)\n",
        "\n",
        "def train_high_res_transform(crop_size):\n",
        "  return transforms.Compose([transforms.RandomCrop(crop_size), transforms.ToTensor()])\n",
        "\n",
        "def train_low_res_transform(crop_size,upscale_factor):\n",
        "  return transforms.Compose([transforms.ToPILImage(), transforms.Resize(crop_size//upscale_factor, interpolation = Image.BICUBIC), transforms.ToTensor()])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Ekv0sK3xkhg9"
      },
      "outputs": [],
      "source": [
        "class TrainDataFromFolder(Dataset):\n",
        "  def __init__(self,data_dir, crop_size, upscale_factor):\n",
        "    super().__init__()\n",
        "    self.image_file_names = [join(data_dir,x) for x in listdir(data_dir) if is_image(x)]\n",
        "    crop_size = calc_valid_crop_size(crop_size, upscale_factor)\n",
        "    self.high_res_transform = train_high_res_transform(crop_size)\n",
        "    self.low_res_transform = train_low_res_transform(crop_size,upscale_factor)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    hr_image = self.high_res_transform(Image.open(self.image_file_names[index]))\n",
        "    lr_image = self.low_res_transform(hr_image)\n",
        "    return lr_image, hr_image\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_file_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1Eg2OiFtlcbt"
      },
      "outputs": [],
      "source": [
        "class ValDataFromFolder(Dataset):\n",
        "  def __init__(self,data_dir, upscale_factor):\n",
        "    super().__init__()\n",
        "    self.upscale_factor = upscale_factor\n",
        "    self.image_file_names = [join(data_dir,x) for x in listdir(data_dir) if is_image(x)]\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    hr_image = Image.open(self.image_file_names[index])\n",
        "    w,h = hr_image.size\n",
        "    crop_size = calc_valid_crop_size(min(w,h), self.upscale_factor)\n",
        "    lr_scale = transforms.Resize(crop_size // self.upscale_factor, interpolation=Image.BICUBIC)\n",
        "    hr_scale = transforms.Resize(crop_size, interpolation=Image.BICUBIC)\n",
        "    hr_image = transforms.CenterCrop(crop_size)(hr_image)\n",
        "    lr_image = lr_scale(hr_image)\n",
        "    hr_restored_image = hr_scale(lr_image)\n",
        "    return transforms.ToTensor()(lr_image), transforms.ToTensor()(hr_restored_image), transforms.ToTensor()(hr_image)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_file_names)\n",
        "    \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq4kn36Bn7Ci",
        "outputId": "75e30bea-2176-4603-f6ef-29cc9f3a83e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "#creating dataset and dataloaders for train and val\n",
        "train_set = TrainDataFromFolder('DIV2K_train_HR', crop_size=crop_size, upscale_factor=upscale_factor)\n",
        "val_set = ValDataFromFolder('DIV2K_valid_HR', upscale_factor=upscale_factor)\n",
        "train_loader = DataLoader(dataset=train_set, num_workers=4, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_set, num_workers=4, batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlbK1eZrwdqn",
        "outputId": "aeeb4bc8-9d9b-4087-b426-7c6dfe21caae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tensor([[[[0.5686, 0.5686, 0.5686,  ..., 0.5725, 0.5725, 0.5686],\n",
            "          [0.5608, 0.5608, 0.5608,  ..., 0.5608, 0.5569, 0.5569],\n",
            "          [0.5529, 0.5490, 0.5529,  ..., 0.5569, 0.5569, 0.5569],\n",
            "          ...,\n",
            "          [0.4235, 0.5608, 0.3529,  ..., 0.2196, 0.2078, 0.1804],\n",
            "          [0.3843, 0.4824, 0.2196,  ..., 0.2157, 0.3294, 0.2863],\n",
            "          [0.2157, 0.3686, 0.3373,  ..., 0.1804, 0.1961, 0.1725]],\n",
            "\n",
            "         [[0.7137, 0.7098, 0.7137,  ..., 0.7176, 0.7137, 0.7137],\n",
            "          [0.7059, 0.7059, 0.7059,  ..., 0.7059, 0.7059, 0.7020],\n",
            "          [0.6980, 0.6980, 0.6980,  ..., 0.7020, 0.7020, 0.7020],\n",
            "          ...,\n",
            "          [0.5294, 0.6353, 0.4784,  ..., 0.3804, 0.3686, 0.3569],\n",
            "          [0.4941, 0.5765, 0.3843,  ..., 0.3882, 0.4392, 0.4000],\n",
            "          [0.3490, 0.4824, 0.4588,  ..., 0.3529, 0.3373, 0.3137]],\n",
            "\n",
            "         [[0.9059, 0.9059, 0.9059,  ..., 0.9098, 0.9098, 0.9059],\n",
            "          [0.8980, 0.9020, 0.9020,  ..., 0.9020, 0.9020, 0.9020],\n",
            "          [0.8902, 0.8902, 0.8902,  ..., 0.8980, 0.8980, 0.8980],\n",
            "          ...,\n",
            "          [0.5529, 0.6667, 0.5412,  ..., 0.4588, 0.4627, 0.4588],\n",
            "          [0.5529, 0.6353, 0.4706,  ..., 0.5176, 0.5373, 0.4824],\n",
            "          [0.3725, 0.5451, 0.5333,  ..., 0.4745, 0.4000, 0.3882]]],\n",
            "\n",
            "\n",
            "        [[[0.4471, 0.4549, 0.4431,  ..., 0.1451, 0.1333, 0.0941],\n",
            "          [0.1961, 0.1804, 0.1608,  ..., 0.0588, 0.0549, 0.0745],\n",
            "          [0.0667, 0.0431, 0.0588,  ..., 0.1216, 0.1216, 0.1098],\n",
            "          ...,\n",
            "          [0.5333, 0.2902, 0.1725,  ..., 0.0980, 0.0745, 0.0824],\n",
            "          [0.6275, 0.5961, 0.5529,  ..., 0.1490, 0.1451, 0.1373],\n",
            "          [0.6824, 0.6314, 0.5216,  ..., 0.2706, 0.2039, 0.1451]],\n",
            "\n",
            "         [[0.3961, 0.3961, 0.3686,  ..., 0.1020, 0.1059, 0.0745],\n",
            "          [0.1647, 0.1569, 0.1373,  ..., 0.0667, 0.0588, 0.0667],\n",
            "          [0.0588, 0.0431, 0.0471,  ..., 0.0745, 0.0784, 0.0667],\n",
            "          ...,\n",
            "          [0.4157, 0.2039, 0.1098,  ..., 0.0510, 0.0353, 0.0510],\n",
            "          [0.4706, 0.4118, 0.3804,  ..., 0.0784, 0.0745, 0.0745],\n",
            "          [0.5961, 0.5098, 0.4000,  ..., 0.1451, 0.1020, 0.0745]],\n",
            "\n",
            "         [[0.3804, 0.3686, 0.3412,  ..., 0.1255, 0.1412, 0.1176],\n",
            "          [0.1608, 0.1529, 0.1451,  ..., 0.1020, 0.0941, 0.1059],\n",
            "          [0.0863, 0.0667, 0.0706,  ..., 0.1059, 0.1098, 0.0980],\n",
            "          ...,\n",
            "          [0.2784, 0.1412, 0.0824,  ..., 0.0667, 0.0510, 0.0745],\n",
            "          [0.2431, 0.1333, 0.1255,  ..., 0.0863, 0.0941, 0.1020],\n",
            "          [0.5137, 0.3608, 0.2196,  ..., 0.0510, 0.0745, 0.0784]]],\n",
            "\n",
            "\n",
            "        [[[0.5098, 0.4471, 0.2235,  ..., 0.8980, 0.8118, 0.4157],\n",
            "          [0.5059, 0.4706, 0.2549,  ..., 0.8549, 0.4706, 0.6588],\n",
            "          [0.4980, 0.4902, 0.2863,  ..., 0.4824, 0.6000, 0.7412],\n",
            "          ...,\n",
            "          [0.4941, 0.5059, 0.4196,  ..., 0.5529, 0.2863, 0.1529],\n",
            "          [0.5020, 0.5020, 0.4275,  ..., 0.4157, 0.3961, 0.2784],\n",
            "          [0.5059, 0.5020, 0.4471,  ..., 0.3529, 0.3333, 0.4275]],\n",
            "\n",
            "         [[0.5137, 0.4510, 0.2196,  ..., 0.8902, 0.8078, 0.4039],\n",
            "          [0.5098, 0.4745, 0.2510,  ..., 0.8510, 0.4627, 0.6510],\n",
            "          [0.5020, 0.4941, 0.2863,  ..., 0.4784, 0.5922, 0.7294],\n",
            "          ...,\n",
            "          [0.4980, 0.5098, 0.4235,  ..., 0.5451, 0.2824, 0.1490],\n",
            "          [0.5059, 0.5059, 0.4314,  ..., 0.4078, 0.3961, 0.2745],\n",
            "          [0.5098, 0.5059, 0.4510,  ..., 0.3490, 0.3294, 0.4196]],\n",
            "\n",
            "         [[0.5255, 0.4588, 0.2431,  ..., 0.9059, 0.8471, 0.4980],\n",
            "          [0.5176, 0.4784, 0.2706,  ..., 0.8824, 0.5451, 0.7059],\n",
            "          [0.5059, 0.4941, 0.3020,  ..., 0.5490, 0.6471, 0.7765],\n",
            "          ...,\n",
            "          [0.5059, 0.5176, 0.4314,  ..., 0.6353, 0.4039, 0.2824],\n",
            "          [0.5137, 0.5137, 0.4392,  ..., 0.5137, 0.5176, 0.4078],\n",
            "          [0.5176, 0.5137, 0.4588,  ..., 0.4627, 0.4627, 0.5333]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0.1020, 0.4314, 0.5020,  ..., 0.2039, 0.3176, 0.4118],\n",
            "          [0.3922, 0.4745, 0.4431,  ..., 0.1961, 0.1412, 0.2353],\n",
            "          [0.5686, 0.5098, 0.2549,  ..., 0.2510, 0.1255, 0.0980],\n",
            "          ...,\n",
            "          [0.2275, 0.2235, 0.3059,  ..., 0.3020, 0.3529, 0.3647],\n",
            "          [0.2275, 0.2235, 0.3216,  ..., 0.2353, 0.3725, 0.3529],\n",
            "          [0.3020, 0.2667, 0.3216,  ..., 0.2118, 0.3765, 0.3490]],\n",
            "\n",
            "         [[0.3059, 0.6157, 0.7137,  ..., 0.4471, 0.5647, 0.6431],\n",
            "          [0.5961, 0.7020, 0.6431,  ..., 0.4196, 0.3451, 0.4667],\n",
            "          [0.7412, 0.6902, 0.4588,  ..., 0.4902, 0.3255, 0.2863],\n",
            "          ...,\n",
            "          [0.4471, 0.3686, 0.5137,  ..., 0.5490, 0.6078, 0.6431],\n",
            "          [0.4588, 0.3373, 0.5294,  ..., 0.4627, 0.6314, 0.6196],\n",
            "          [0.5373, 0.4078, 0.5412,  ..., 0.4275, 0.6392, 0.6118]],\n",
            "\n",
            "         [[0.0353, 0.3373, 0.3882,  ..., 0.0000, 0.1020, 0.1961],\n",
            "          [0.3059, 0.3412, 0.3216,  ..., 0.0039, 0.0000, 0.0275],\n",
            "          [0.4471, 0.4078, 0.1333,  ..., 0.0039, 0.0039, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0078, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0039],\n",
            "          [0.0588, 0.0157, 0.0039,  ..., 0.0039, 0.0039, 0.0039]]],\n",
            "\n",
            "\n",
            "        [[[0.9725, 0.8706, 0.9490,  ..., 0.8824, 0.7137, 0.8118],\n",
            "          [0.9843, 0.9059, 0.9569,  ..., 0.8549, 0.8157, 0.8039],\n",
            "          [0.9843, 0.9137, 0.9647,  ..., 0.8000, 0.8275, 0.8471],\n",
            "          ...,\n",
            "          [0.9843, 0.8588, 0.8392,  ..., 0.7647, 0.7804, 0.9059],\n",
            "          [0.9882, 0.8353, 0.8314,  ..., 0.8392, 0.8471, 0.8863],\n",
            "          [0.9922, 0.8745, 0.8941,  ..., 0.8863, 0.9020, 0.8980]],\n",
            "\n",
            "         [[0.9059, 0.7020, 0.8118,  ..., 0.7451, 0.6941, 0.7725],\n",
            "          [0.9255, 0.7529, 0.8196,  ..., 0.6549, 0.7529, 0.7765],\n",
            "          [0.9255, 0.7569, 0.8235,  ..., 0.5686, 0.6627, 0.8078],\n",
            "          ...,\n",
            "          [0.9216, 0.6902, 0.6549,  ..., 0.6157, 0.5451, 0.7098],\n",
            "          [0.9216, 0.6667, 0.6510,  ..., 0.6941, 0.6588, 0.6667],\n",
            "          [0.9294, 0.7216, 0.7725,  ..., 0.7373, 0.7804, 0.7216]],\n",
            "\n",
            "         [[0.8510, 0.5451, 0.6784,  ..., 0.5882, 0.6510, 0.7137],\n",
            "          [0.8824, 0.6078, 0.6745,  ..., 0.4314, 0.6706, 0.7333],\n",
            "          [0.8784, 0.6078, 0.6784,  ..., 0.3294, 0.4863, 0.7569],\n",
            "          ...,\n",
            "          [0.8627, 0.5294, 0.4549,  ..., 0.4784, 0.3098, 0.4980],\n",
            "          [0.8627, 0.5020, 0.4588,  ..., 0.5647, 0.4706, 0.4275],\n",
            "          [0.8745, 0.5686, 0.6549,  ..., 0.6039, 0.6549, 0.5216]]],\n",
            "\n",
            "\n",
            "        [[[0.0353, 0.0667, 0.0667,  ..., 0.0549, 0.0431, 0.0314],\n",
            "          [0.0196, 0.0471, 0.0627,  ..., 0.0510, 0.0510, 0.0392],\n",
            "          [0.0078, 0.0275, 0.0588,  ..., 0.0549, 0.0510, 0.0392],\n",
            "          ...,\n",
            "          [0.0431, 0.0235, 0.0431,  ..., 0.0431, 0.0314, 0.0275],\n",
            "          [0.0588, 0.0314, 0.0431,  ..., 0.0510, 0.0314, 0.0275],\n",
            "          [0.0784, 0.0706, 0.0392,  ..., 0.0471, 0.0353, 0.0353]],\n",
            "\n",
            "         [[0.0353, 0.0667, 0.0667,  ..., 0.0549, 0.0431, 0.0314],\n",
            "          [0.0196, 0.0471, 0.0627,  ..., 0.0471, 0.0510, 0.0392],\n",
            "          [0.0118, 0.0275, 0.0588,  ..., 0.0549, 0.0510, 0.0392],\n",
            "          ...,\n",
            "          [0.0431, 0.0235, 0.0353,  ..., 0.0431, 0.0314, 0.0275],\n",
            "          [0.0549, 0.0314, 0.0353,  ..., 0.0471, 0.0314, 0.0275],\n",
            "          [0.0784, 0.0706, 0.0392,  ..., 0.0471, 0.0353, 0.0353]],\n",
            "\n",
            "         [[0.0275, 0.0588, 0.0588,  ..., 0.0471, 0.0353, 0.0235],\n",
            "          [0.0157, 0.0392, 0.0549,  ..., 0.0392, 0.0392, 0.0314],\n",
            "          [0.0118, 0.0196, 0.0510,  ..., 0.0471, 0.0392, 0.0314],\n",
            "          ...,\n",
            "          [0.0392, 0.0196, 0.0314,  ..., 0.0353, 0.0235, 0.0196],\n",
            "          [0.0510, 0.0314, 0.0353,  ..., 0.0431, 0.0235, 0.0196],\n",
            "          [0.0706, 0.0627, 0.0353,  ..., 0.0392, 0.0275, 0.0275]]]]), tensor([[[[0.5765, 0.5725, 0.5725,  ..., 0.5725, 0.5765, 0.5725],\n",
            "          [0.5725, 0.5765, 0.5725,  ..., 0.5647, 0.5647, 0.5686],\n",
            "          [0.5765, 0.5765, 0.5686,  ..., 0.5686, 0.5647, 0.5686],\n",
            "          ...,\n",
            "          [0.1412, 0.1333, 0.1373,  ..., 0.1412, 0.1294, 0.1176],\n",
            "          [0.1608, 0.1765, 0.2118,  ..., 0.1098, 0.1255, 0.1137],\n",
            "          [0.2549, 0.2863, 0.2627,  ..., 0.1098, 0.1176, 0.1569]],\n",
            "\n",
            "         [[0.7176, 0.7137, 0.7176,  ..., 0.7216, 0.7255, 0.7216],\n",
            "          [0.7137, 0.7176, 0.7176,  ..., 0.7137, 0.7176, 0.7176],\n",
            "          [0.7137, 0.7176, 0.7098,  ..., 0.7137, 0.7137, 0.7176],\n",
            "          ...,\n",
            "          [0.2745, 0.2627, 0.2627,  ..., 0.2941, 0.2824, 0.2706],\n",
            "          [0.2902, 0.2941, 0.3216,  ..., 0.2667, 0.2824, 0.2667],\n",
            "          [0.3725, 0.3922, 0.3686,  ..., 0.2627, 0.2706, 0.3098]],\n",
            "\n",
            "         [[0.9137, 0.9098, 0.9137,  ..., 0.9137, 0.9176, 0.9137],\n",
            "          [0.9098, 0.9137, 0.9098,  ..., 0.9098, 0.9098, 0.9098],\n",
            "          [0.9098, 0.9137, 0.9059,  ..., 0.9137, 0.9059, 0.9098],\n",
            "          ...,\n",
            "          [0.3059, 0.2980, 0.2941,  ..., 0.3765, 0.3725, 0.3569],\n",
            "          [0.3059, 0.3098, 0.3373,  ..., 0.3725, 0.3765, 0.3647],\n",
            "          [0.3373, 0.3569, 0.3451,  ..., 0.3686, 0.3686, 0.4000]]],\n",
            "\n",
            "\n",
            "        [[[0.5412, 0.5020, 0.6039,  ..., 0.1412, 0.1255, 0.1176],\n",
            "          [0.5176, 0.4392, 0.5059,  ..., 0.1294, 0.1216, 0.1137],\n",
            "          [0.4510, 0.4235, 0.4196,  ..., 0.1255, 0.1294, 0.1412],\n",
            "          ...,\n",
            "          [0.7686, 0.7529, 0.7412,  ..., 0.1373, 0.1255, 0.1569],\n",
            "          [0.6667, 0.6863, 0.7373,  ..., 0.1412, 0.1294, 0.1569],\n",
            "          [0.6196, 0.6196, 0.6980,  ..., 0.1490, 0.1451, 0.1412]],\n",
            "\n",
            "         [[0.4980, 0.4392, 0.5059,  ..., 0.0941, 0.0784, 0.0667],\n",
            "          [0.4824, 0.4000, 0.4314,  ..., 0.0824, 0.0745, 0.0706],\n",
            "          [0.4157, 0.3882, 0.3804,  ..., 0.0784, 0.0784, 0.0902],\n",
            "          ...,\n",
            "          [0.6706, 0.6706, 0.6824,  ..., 0.0706, 0.0627, 0.0980],\n",
            "          [0.5686, 0.5961, 0.6784,  ..., 0.0706, 0.0667, 0.0941],\n",
            "          [0.5059, 0.5098, 0.6118,  ..., 0.0706, 0.0745, 0.0784]],\n",
            "\n",
            "         [[0.4980, 0.4157, 0.4784,  ..., 0.1373, 0.1176, 0.1098],\n",
            "          [0.4941, 0.4118, 0.4275,  ..., 0.1255, 0.1137, 0.1098],\n",
            "          [0.4314, 0.4000, 0.3843,  ..., 0.1255, 0.1176, 0.1333],\n",
            "          ...,\n",
            "          [0.6235, 0.6314, 0.6431,  ..., 0.0784, 0.0824, 0.1176],\n",
            "          [0.4235, 0.4863, 0.6078,  ..., 0.0824, 0.0863, 0.1137],\n",
            "          [0.2941, 0.3412, 0.4980,  ..., 0.0784, 0.0824, 0.0863]]],\n",
            "\n",
            "\n",
            "        [[[0.5020, 0.5725, 0.5412,  ..., 0.2314, 0.2235, 0.2039],\n",
            "          [0.5098, 0.5569, 0.5412,  ..., 0.3137, 0.2118, 0.2902],\n",
            "          [0.5216, 0.4824, 0.5529,  ..., 0.2627, 0.2353, 0.4980],\n",
            "          ...,\n",
            "          [0.4824, 0.4627, 0.4549,  ..., 0.8980, 0.3882, 0.2627],\n",
            "          [0.4353, 0.4902, 0.4039,  ..., 1.0000, 0.7020, 0.2471],\n",
            "          [0.5490, 0.5529, 0.4784,  ..., 0.9961, 0.9098, 0.4980]],\n",
            "\n",
            "         [[0.5059, 0.5765, 0.5451,  ..., 0.2196, 0.2118, 0.1882],\n",
            "          [0.5137, 0.5608, 0.5451,  ..., 0.3020, 0.2000, 0.2745],\n",
            "          [0.5255, 0.4863, 0.5569,  ..., 0.2510, 0.2235, 0.4863],\n",
            "          ...,\n",
            "          [0.4863, 0.4667, 0.4588,  ..., 0.8784, 0.3529, 0.2353],\n",
            "          [0.4392, 0.4941, 0.4118,  ..., 1.0000, 0.6902, 0.2275],\n",
            "          [0.5529, 0.5569, 0.4863,  ..., 0.9922, 0.9059, 0.4902]],\n",
            "\n",
            "         [[0.5137, 0.5843, 0.5529,  ..., 0.3373, 0.3255, 0.3059],\n",
            "          [0.5216, 0.5686, 0.5529,  ..., 0.4118, 0.3137, 0.3843],\n",
            "          [0.5333, 0.4941, 0.5647,  ..., 0.3647, 0.3333, 0.5922],\n",
            "          ...,\n",
            "          [0.4941, 0.4745, 0.4667,  ..., 0.9255, 0.4471, 0.3608],\n",
            "          [0.4471, 0.4980, 0.4078,  ..., 1.0000, 0.7490, 0.3294],\n",
            "          [0.5608, 0.5647, 0.4902,  ..., 1.0000, 0.9569, 0.5961]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0.1490, 0.1137, 0.0941,  ..., 0.2314, 0.1843, 0.1804],\n",
            "          [0.1333, 0.1098, 0.0980,  ..., 0.2471, 0.2275, 0.2157],\n",
            "          [0.1294, 0.1176, 0.0941,  ..., 0.3098, 0.2314, 0.1961],\n",
            "          ...,\n",
            "          [0.4078, 0.4196, 0.4196,  ..., 0.3529, 0.3608, 0.3725],\n",
            "          [0.4902, 0.4902, 0.4784,  ..., 0.3412, 0.3373, 0.3647],\n",
            "          [0.5412, 0.5451, 0.5569,  ..., 0.3412, 0.3608, 0.3686]],\n",
            "\n",
            "         [[0.4000, 0.3529, 0.3176,  ..., 0.4549, 0.3882, 0.3922],\n",
            "          [0.3725, 0.3490, 0.3294,  ..., 0.4745, 0.4549, 0.4471],\n",
            "          [0.3765, 0.3569, 0.3216,  ..., 0.5451, 0.4431, 0.4157],\n",
            "          ...,\n",
            "          [0.6745, 0.6824, 0.6863,  ..., 0.6157, 0.6235, 0.6392],\n",
            "          [0.7137, 0.7098, 0.6980,  ..., 0.6039, 0.6000, 0.6275],\n",
            "          [0.7373, 0.7333, 0.7451,  ..., 0.6039, 0.6157, 0.6235]],\n",
            "\n",
            "         [[0.0000, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
            "          [0.0000, 0.0039, 0.0039,  ..., 0.0039, 0.0000, 0.0039],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0039, 0.0039],\n",
            "          ...,\n",
            "          [0.0353, 0.0314, 0.0235,  ..., 0.0039, 0.0039, 0.0000],\n",
            "          [0.2471, 0.2353, 0.2275,  ..., 0.0039, 0.0078, 0.0039],\n",
            "          [0.3804, 0.3725, 0.3843,  ..., 0.0000, 0.0039, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.9843, 0.9843, 0.9843,  ..., 0.9882, 0.9647, 0.9020],\n",
            "          [0.9843, 0.9843, 0.9843,  ..., 0.9882, 0.9647, 0.9098],\n",
            "          [0.9843, 0.9804, 0.9843,  ..., 0.9882, 0.9686, 0.9098],\n",
            "          ...,\n",
            "          [0.9843, 0.9804, 0.9804,  ..., 0.8824, 0.9412, 0.9569],\n",
            "          [0.9843, 0.9804, 0.9804,  ..., 0.8196, 0.8902, 0.9294],\n",
            "          [0.9843, 0.9843, 0.9843,  ..., 0.8078, 0.8235, 0.8902]],\n",
            "\n",
            "         [[0.9216, 0.9216, 0.9216,  ..., 0.9412, 0.9020, 0.7686],\n",
            "          [0.9216, 0.9216, 0.9216,  ..., 0.9451, 0.9020, 0.7765],\n",
            "          [0.9216, 0.9176, 0.9216,  ..., 0.9451, 0.9059, 0.7765],\n",
            "          ...,\n",
            "          [0.9216, 0.9176, 0.9176,  ..., 0.6314, 0.6902, 0.7176],\n",
            "          [0.9216, 0.9176, 0.9176,  ..., 0.5804, 0.6471, 0.6941],\n",
            "          [0.9216, 0.9216, 0.9216,  ..., 0.6314, 0.5961, 0.6627]],\n",
            "\n",
            "         [[0.8627, 0.8627, 0.8627,  ..., 0.9216, 0.8510, 0.6392],\n",
            "          [0.8627, 0.8627, 0.8627,  ..., 0.9176, 0.8431, 0.6392],\n",
            "          [0.8627, 0.8588, 0.8667,  ..., 0.9176, 0.8392, 0.6275],\n",
            "          ...,\n",
            "          [0.8627, 0.8588, 0.8588,  ..., 0.3765, 0.4196, 0.4667],\n",
            "          [0.8627, 0.8588, 0.8588,  ..., 0.3255, 0.3922, 0.4353],\n",
            "          [0.8627, 0.8627, 0.8627,  ..., 0.4157, 0.3255, 0.3765]]],\n",
            "\n",
            "\n",
            "        [[[0.0118, 0.0157, 0.0235,  ..., 0.0431, 0.0392, 0.0392],\n",
            "          [0.0118, 0.0196, 0.0275,  ..., 0.0392, 0.0471, 0.0392],\n",
            "          [0.0118, 0.0196, 0.0275,  ..., 0.0353, 0.0353, 0.0431],\n",
            "          ...,\n",
            "          [0.0745, 0.0824, 0.0784,  ..., 0.0353, 0.0353, 0.0353],\n",
            "          [0.0784, 0.0863, 0.0863,  ..., 0.0431, 0.0392, 0.0392],\n",
            "          [0.0784, 0.0902, 0.0824,  ..., 0.0471, 0.0392, 0.0471]],\n",
            "\n",
            "         [[0.0118, 0.0157, 0.0235,  ..., 0.0431, 0.0392, 0.0392],\n",
            "          [0.0118, 0.0196, 0.0275,  ..., 0.0392, 0.0471, 0.0392],\n",
            "          [0.0118, 0.0196, 0.0275,  ..., 0.0353, 0.0353, 0.0431],\n",
            "          ...,\n",
            "          [0.0745, 0.0824, 0.0784,  ..., 0.0353, 0.0353, 0.0353],\n",
            "          [0.0784, 0.0863, 0.0863,  ..., 0.0431, 0.0392, 0.0392],\n",
            "          [0.0784, 0.0902, 0.0824,  ..., 0.0471, 0.0392, 0.0471]],\n",
            "\n",
            "         [[0.0118, 0.0157, 0.0235,  ..., 0.0353, 0.0314, 0.0314],\n",
            "          [0.0118, 0.0196, 0.0275,  ..., 0.0314, 0.0353, 0.0314],\n",
            "          [0.0118, 0.0196, 0.0275,  ..., 0.0314, 0.0314, 0.0392],\n",
            "          ...,\n",
            "          [0.0667, 0.0745, 0.0706,  ..., 0.0275, 0.0275, 0.0275],\n",
            "          [0.0706, 0.0784, 0.0784,  ..., 0.0353, 0.0314, 0.0314],\n",
            "          [0.0706, 0.0824, 0.0745,  ..., 0.0392, 0.0314, 0.0392]]]])]\n"
          ]
        }
      ],
      "source": [
        "for batch in train_loader:\n",
        "  print(batch)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1NICVDZmo3bt"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self, channels):\n",
        "    super(ResidualBlock, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "    self.bn1 = nn.BatchNorm2d(channels)\n",
        "    self.prelu = nn.PReLU()\n",
        "    self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "    self.bn2 = nn.BatchNorm2d(channels)\n",
        "  def forward(self, x):\n",
        "    residual = self.conv1(x)\n",
        "    residual = self.bn1(residual)\n",
        "    residual = self.prelu(residual)\n",
        "    residual = self.conv2(residual)\n",
        "    residual = self.bn2(residual)\n",
        "    return x + residual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "sgkY3bxfo3i5"
      },
      "outputs": [],
      "source": [
        "class UpsampleBlock(nn.Module):\n",
        "  def __init__(self, in_channels, up_scale):\n",
        "    super(UpsampleBlock, self).__init__()\n",
        "    self.conv = nn.Conv2d(in_channels, in_channels * up_scale ** 2, \n",
        "                          kernel_size=3, padding=1)\n",
        "    self.pixel_shuffle = nn.PixelShuffle(up_scale)\n",
        "    self.prelu = nn.PReLU()\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    x = self.pixel_shuffle(x)\n",
        "    x = self.prelu(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14O3cfi76NJW"
      },
      "source": [
        "> Generator Model Architecture\n",
        "- It is a fully conv SR Resnet Model. First LQ image is passed through kernel of 9*9 followed by parametric RelU. \n",
        "- The output of PReLU is fed to next set of residual block. Inside each residual network block, There are 2 cnn blocks with kernel 3*3 followed by BN and Prelu as activation. \n",
        "- Element wise sum - i.e residual block batch norm output is added with Prelu output of prev. layer. Pixel shuffler is used to increase image size by 8. At the end, We can assume HQ image after this.\n",
        "- Pixel shuffle converts number of channels into Height and Width.\n",
        "- Various blocks are added to generate HQ image eventually."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ttET7xBBo3mw"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, scale_factor):\n",
        "    super(Generator, self).__init__()\n",
        "    upsample_block_num = int(math.log(scale_factor, 2))\n",
        "\n",
        "    self.block1 = nn.Sequential(\n",
        "        nn.Conv2d(3, 64, kernel_size=9, padding=4),\n",
        "        nn.PReLU()\n",
        "    )\n",
        "\n",
        "    self.block2 = ResidualBlock(64)\n",
        "    self.block3 = ResidualBlock(64)\n",
        "    self.block4 = ResidualBlock(64)\n",
        "    self.block5 = ResidualBlock(64)\n",
        "    self.block6 = ResidualBlock(64)\n",
        "    self.block7 = nn.Sequential(\n",
        "        nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(64)\n",
        "    )\n",
        "    block8 = [UpsampleBlock(64, 2) for _ in range(upsample_block_num)]\n",
        "    block8.append(nn.Conv2d(64, 3, kernel_size=9, padding=4))\n",
        "    self.block8 = nn.Sequential(*block8)\n",
        "  def forward(self, x):\n",
        "    block1 = self.block1(x)\n",
        "    block2 = self.block2(block1)\n",
        "    block3 = self.block3(block2)\n",
        "    block4 = self.block4(block3)\n",
        "    block5 = self.block5(block4)\n",
        "    block6 = self.block6(block5)\n",
        "    block7 = self.block7(block6)\n",
        "    block8 = self.block8(block1 + block7)\n",
        "    return (torch.tanh(block8) + 1) / 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqxYbIAd7cS7"
      },
      "source": [
        "> Discriminator Model\n",
        "- It is an image classification model to decipher whether the generate HQ image is real or fake.\n",
        "- It expects two inputs i.e output of generator and real HQ image from dataset.\n",
        "- It has blocks of Conv2D, BatchNorm and Leaky ReLU. 8 conv layer with 3*3 kernels with feature size by a factor of 2, starting from 64.\n",
        "- output is fed to dense layer then sigmoid layer to obtain probability whether the image is fake or real."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "gIpOIiaWo3qF"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.AdaptiveAvgPool2d(1),\n",
        "        nn.Conv2d(512, 1024, kernel_size=1),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Conv2d(1024, 1, kernel_size=1)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    batch_size=x.size()[0]\n",
        "    return torch.sigmoid(self.net(x).view(batch_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "GjBxuCN-pEz1"
      },
      "outputs": [],
      "source": [
        "class TVLoss(nn.Module):\n",
        "  def __init__(self, tv_loss_weight=1):\n",
        "    super(TVLoss, self).__init__()\n",
        "    self.tv_loss_weight=tv_loss_weight\n",
        "  def forward(self, x):\n",
        "    batch_size=x.size()[0]\n",
        "    h_x = x.size()[2]\n",
        "    w_x = x.size()[3]\n",
        "\n",
        "    count_h = self.tensor_size(x[:, :, 1:, :])\n",
        "    count_w = self.tensor_size(x[:, :, :, 1:])\n",
        "\n",
        "    h_tv = torch.pow(x[:, :, 1:, :] - x[:, :, :h_x - 1, :], 2).sum()\n",
        "    w_tv = torch.pow(x[:, :, :, 1:] - x[:, :, :, :w_x - 1], 2).sum()\n",
        "    return self.tv_loss_weight * 2 * (h_tv / count_h + w_tv / count_w) / batch_size\n",
        "  \n",
        "  @staticmethod \n",
        "  def tensor_size(t):\n",
        "    return t.size()[1] * t.size()[2] * t.size()[3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "jyaRNuHspE2j"
      },
      "outputs": [],
      "source": [
        "class GeneratorLoss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(GeneratorLoss, self).__init__()\n",
        "    vgg = vgg16(pretrained=True)\n",
        "    loss_network = nn.Sequential(*list(vgg.features)[:31]).eval()\n",
        "    for param in loss_network.parameters():\n",
        "      param.requires_grad = False\n",
        "    self.loss_network = loss_network\n",
        "    self.mse_loss = nn.MSELoss()\n",
        "    self.tv_loss = TVLoss()\n",
        "  def forward(self, out_labels, out_images, target_images):\n",
        "    adversial_loss = torch.mean(1 - out_labels)\n",
        "    perception_loss = self.mse_loss(out_images, target_images)\n",
        "    image_loss = self.mse_loss(out_images, target_images)\n",
        "    tv_loss = self.tv_loss(out_images)\n",
        "    return image_loss + 0.001 * adversial_loss + 0.006 * perception_loss + 2e-8 * tv_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "4nRfqePVpE44"
      },
      "outputs": [],
      "source": [
        "netG = Generator(upscale_factor)\n",
        "netD = Discriminator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165,
          "referenced_widgets": [
            "17f7320c1455408983858c70bba43185",
            "d33884835ce74b9492563872e137dee9",
            "b9b0e111bfa1436db32808a43abbc0c9",
            "0cadf6a3b92f4a8f8c92e00cb8872bb6",
            "bc34302ea074489ab3a75048dfaad892",
            "75507366d54b4006ae015c433298aece",
            "fefd79ab244c471880fa6440a445d637",
            "eb4488196862488fab0ab286a3c57fd9",
            "59cd79707c6d46ce9fe85cb4d1f6e562",
            "43e43d4b9e9c482386ef52b3618235c7",
            "99e81c0524c540059435dec8c52b0470"
          ]
        },
        "id": "uhg2xQrjpE7W",
        "outputId": "f075b951-5455-45c5-f9a0-1924299f74d2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17f7320c1455408983858c70bba43185",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/528M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "generator_criterion = GeneratorLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "0YLb_lKcpE-F"
      },
      "outputs": [],
      "source": [
        "generator_criterion = generator_criterion.to(device)\n",
        "netG = netG.to(device)\n",
        "netD = netD.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "j4EYg0t7pR_q"
      },
      "outputs": [],
      "source": [
        "optimizerG = optim.Adam(netG.parameters(), lr=0.0002)\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=0.0002)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "vsxD230JsgKk"
      },
      "outputs": [],
      "source": [
        "def gaussian(window_size, sigma):\n",
        "    gauss = torch.Tensor([exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\n",
        "    return gauss / gauss.sum()\n",
        "\n",
        "\n",
        "def create_window(window_size, channel):\n",
        "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
        "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
        "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
        "    return window\n",
        "\n",
        "\n",
        "def _ssim(img1, img2, window, window_size, channel, size_average=True):\n",
        "    mu1 = F.conv2d(img1, window, padding=window_size // 2, groups=channel)\n",
        "    mu2 = F.conv2d(img2, window, padding=window_size // 2, groups=channel)\n",
        "\n",
        "    mu1_sq = mu1.pow(2)\n",
        "    mu2_sq = mu2.pow(2)\n",
        "    mu1_mu2 = mu1 * mu2\n",
        "\n",
        "    sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size // 2, groups=channel) - mu1_sq\n",
        "    sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size // 2, groups=channel) - mu2_sq\n",
        "    sigma12 = F.conv2d(img1 * img2, window, padding=window_size // 2, groups=channel) - mu1_mu2\n",
        "\n",
        "    C1 = 0.01 ** 2\n",
        "    C2 = 0.03 ** 2\n",
        "\n",
        "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
        "\n",
        "    if size_average:\n",
        "        return ssim_map.mean()\n",
        "    else:\n",
        "        return ssim_map.mean(1).mean(1).mean(1)\n",
        "\n",
        "def ssim(img1, img2, window_size=11, size_average=True):\n",
        "    (_, channel, _, _) = img1.size()\n",
        "    window = create_window(window_size, channel)\n",
        "\n",
        "    if img1.is_cuda:\n",
        "        window = window.cuda(img1.get_device())\n",
        "    window = window.type_as(img1)\n",
        "\n",
        "    return _ssim(img1, img2, window, window_size, channel, size_average)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "4Wu7icifpTTr"
      },
      "outputs": [],
      "source": [
        "results = {'d_loss': [], 'g_loss': [], 'd_score': [], 'g_score': [], 'psnr': [], 'ssim': []}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFWQMGzmresN"
      },
      "source": [
        "- Mean square loss is often not great since it compares pixel values, SSIM(Structural similarity) tries to capture the structure of image including noise via statistic. SSIM looks at groups of pixels to decipher whether two images are same or not.\n",
        "- psnr is peak signal to noise ratio used as yet another metric.\n",
        "- TV loss obtains better edges by doing total variation(TV) on the reconstructed image and the residual between the reconstructed image and the original image.\n",
        "- Training model simultaneously."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EdSJN-RopiH0",
        "outputId": "5408c882-c4e6-4116-8985-777ff5c9a960"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "[1/100] Loss_D: 0.7321 Loss_G: 0.0193 D(x): 0.6650 D(G(z)): 0.3485: 100%|██████████| 13/13 [01:04<00:00,  4.94s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "[converting LR images to SR images] PSNR: 17.4907 dB SSIM: 0.4616: 100%|██████████| 100/100 [00:28<00:00,  3.47it/s]\n",
            "[2/100] Loss_D: 0.4095 Loss_G: 0.0173 D(x): 0.7983 D(G(z)): 0.1938: 100%|██████████| 13/13 [00:59<00:00,  4.58s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "[converting LR images to SR images] PSNR: 18.4509 dB SSIM: 0.4923: 100%|██████████| 100/100 [00:27<00:00,  3.58it/s]\n",
            "[3/100] Loss_D: 0.2897 Loss_G: 0.0149 D(x): 0.7975 D(G(z)): 0.0666: 100%|██████████| 13/13 [01:00<00:00,  4.66s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "[converting LR images to SR images] PSNR: 18.8003 dB SSIM: 0.5053: 100%|██████████| 100/100 [00:27<00:00,  3.61it/s]\n",
            "[4/100] Loss_D: 0.1016 Loss_G: 0.0145 D(x): 0.9190 D(G(z)): 0.0177: 100%|██████████| 13/13 [01:04<00:00,  4.99s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "[converting LR images to SR images] PSNR: 18.9439 dB SSIM: 0.5229: 100%|██████████| 100/100 [00:28<00:00,  3.49it/s]\n",
            "[5/100] Loss_D: 0.0542 Loss_G: 0.0131 D(x): 0.9642 D(G(z)): 0.0163: 100%|██████████| 13/13 [01:02<00:00,  4.82s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "[converting LR images to SR images] PSNR: 19.6261 dB SSIM: 0.5336: 100%|██████████| 100/100 [00:28<00:00,  3.46it/s]\n",
            "[6/100] Loss_D: 0.0202 Loss_G: 0.0124 D(x): 0.9901 D(G(z)): 0.0095: 100%|██████████| 13/13 [01:03<00:00,  4.92s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "[converting LR images to SR images] PSNR: 19.5165 dB SSIM: 0.5294: 100%|██████████| 100/100 [00:28<00:00,  3.49it/s]\n",
            "[7/100] Loss_D: 0.0133 Loss_G: 0.0119 D(x): 0.9932 D(G(z)): 0.0056: 100%|██████████| 13/13 [00:59<00:00,  4.58s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "[converting LR images to SR images] PSNR: 19.1007 dB SSIM: 0.5443: 100%|██████████| 100/100 [00:28<00:00,  3.57it/s]\n",
            "[8/100] Loss_D: 0.0113 Loss_G: 0.0130 D(x): 0.9927 D(G(z)): 0.0040: 100%|██████████| 13/13 [00:58<00:00,  4.48s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "[converting LR images to SR images] PSNR: 19.9625 dB SSIM: 0.5480: 100%|██████████| 100/100 [00:28<00:00,  3.46it/s]\n",
            "[9/100] Loss_D: 0.0102 Loss_G: 0.0122 D(x): 0.9951 D(G(z)): 0.0041: 100%|██████████| 13/13 [00:59<00:00,  4.61s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "[converting LR images to SR images] PSNR: 20.0355 dB SSIM: 0.5528: 100%|██████████| 100/100 [00:27<00:00,  3.62it/s]\n",
            "[10/100] Loss_D: 0.0081 Loss_G: 0.0120 D(x): 0.9953 D(G(z)): 0.0034: 100%|██████████| 13/13 [00:59<00:00,  4.57s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "[converting LR images to SR images] PSNR: 19.5975 dB SSIM: 0.5518: 100%|██████████| 100/100 [00:27<00:00,  3.62it/s]\n",
            "  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "[11/100] Loss_D: 0.0062 Loss_G: 0.0113 D(x): 0.9975 D(G(z)): 0.0030: 100%|██████████| 13/13 [00:58<00:00,  4.49s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "[converting LR images to SR images] PSNR: 19.8883 dB SSIM: 0.5594: 100%|██████████| 100/100 [00:28<00:00,  3.56it/s]\n",
            "[12/100] Loss_D: 0.0044 Loss_G: 0.0130 D(x): 0.9976 D(G(z)): 0.0019: 100%|██████████| 13/13 [01:08<00:00,  5.30s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "[converting LR images to SR images] PSNR: 19.9765 dB SSIM: 0.5582: 100%|██████████| 100/100 [00:28<00:00,  3.56it/s]\n",
            "[13/100] Loss_D: 0.0032 Loss_G: 0.0115 D(x): 0.9980 D(G(z)): 0.0012: 100%|██████████| 13/13 [01:05<00:00,  5.01s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "[converting LR images to SR images] PSNR: 20.2298 dB SSIM: 0.5631: 100%|██████████| 100/100 [00:27<00:00,  3.57it/s]\n",
            "[14/100] Loss_D: 0.0039 Loss_G: 0.0112 D(x): 0.9980 D(G(z)): 0.0017: 100%|██████████| 13/13 [00:59<00:00,  4.55s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "[converting LR images to SR images] PSNR: 19.7339 dB SSIM: 0.5555: 100%|██████████| 100/100 [00:27<00:00,  3.61it/s]\n",
            "[15/100] Loss_D: 0.0023 Loss_G: 0.0110 D(x): 0.9988 D(G(z)): 0.0011: 100%|██████████| 13/13 [01:03<00:00,  4.89s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "[converting LR images to SR images] PSNR: 20.3458 dB SSIM: 0.5684: 100%|██████████| 100/100 [00:28<00:00,  3.49it/s]\n",
            "[16/100] Loss_D: 0.0019 Loss_G: 0.0108 D(x): 0.9993 D(G(z)): 0.0010: 100%|██████████| 13/13 [01:02<00:00,  4.82s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "[converting LR images to SR images] PSNR: 20.1448 dB SSIM: 0.5640: 100%|██████████| 100/100 [00:28<00:00,  3.56it/s]\n",
            "[17/100] Loss_D: 0.0025 Loss_G: 0.0116 D(x): 0.9985 D(G(z)): 0.0009: 100%|██████████| 13/13 [01:03<00:00,  4.87s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "[converting LR images to SR images] PSNR: 19.8648 dB SSIM: 0.5609: 100%|██████████| 100/100 [00:27<00:00,  3.60it/s]\n",
            "[18/100] Loss_D: 0.0024 Loss_G: 0.0107 D(x): 0.9990 D(G(z)): 0.0012: 100%|██████████| 13/13 [01:08<00:00,  5.24s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "[converting LR images to SR images] PSNR: 20.7003 dB SSIM: 0.5731: 100%|██████████| 100/100 [00:28<00:00,  3.53it/s]\n",
            "[19/100] Loss_D: 0.0973 Loss_G: 0.0103 D(x): 0.9777 D(G(z)): 0.0182: 100%|██████████| 13/13 [01:07<00:00,  5.18s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "[converting LR images to SR images] PSNR: 20.2383 dB SSIM: 0.5661: 100%|██████████| 100/100 [00:30<00:00,  3.33it/s]\n",
            "[20/100] Loss_D: 0.4438 Loss_G: 0.0099 D(x): 0.7713 D(G(z)): 0.1583: 100%|██████████| 13/13 [01:08<00:00,  5.25s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "[converting LR images to SR images] PSNR: 19.1976 dB SSIM: 0.5614: 100%|██████████| 100/100 [00:29<00:00,  3.41it/s]\n",
            "  0%|          | 0/13 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "[21/100] Loss_D: 0.2193 Loss_G: 0.0096 D(x): 0.8609 D(G(z)): 0.0657: 100%|██████████| 13/13 [01:07<00:00,  5.16s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "[converting LR images to SR images] PSNR: 20.5179 dB SSIM: 0.5738: 100%|██████████| 100/100 [00:29<00:00,  3.36it/s]\n",
            "[22/100] Loss_D: 0.1004 Loss_G: 0.0102 D(x): 0.9391 D(G(z)): 0.0526: 100%|██████████| 13/13 [01:08<00:00,  5.26s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "[converting LR images to SR images] PSNR: 20.0486 dB SSIM: 0.5645: 100%|██████████| 100/100 [00:28<00:00,  3.51it/s]\n",
            "[23/100] Loss_D: 0.1820 Loss_G: 0.0102 D(x): 0.9461 D(G(z)): 0.0732: 100%|██████████| 13/13 [01:07<00:00,  5.19s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "[converting LR images to SR images] PSNR: 21.1416 dB SSIM: 0.5769: 100%|██████████| 100/100 [00:28<00:00,  3.52it/s]\n",
            "[24/100] Loss_D: 0.0255 Loss_G: 0.0089 D(x): 0.9879 D(G(z)): 0.0112: 100%|██████████| 13/13 [01:06<00:00,  5.15s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "[converting LR images to SR images] PSNR: 20.9952 dB SSIM: 0.5829: 100%|██████████| 100/100 [00:28<00:00,  3.49it/s]\n",
            "[25/100] Loss_D: 0.0105 Loss_G: 0.0091 D(x): 0.9958 D(G(z)): 0.0055:  85%|████████▍ | 11/13 [01:03<00:11,  5.74s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-076b545e2d01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;31m##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mfake_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for epoch in range(1, num_epochs + 1):\n",
        "        train_bar = tqdm(train_loader)\n",
        "        running_results = {'batch_sizes': 0, 'd_loss': 0, 'g_loss': 0, 'd_score': 0, 'g_score': 0}\n",
        "    \n",
        "        netG.train()\n",
        "        netD.train()\n",
        "        for data, target in train_bar:\n",
        "            g_update_first = True\n",
        "            batch_size = data.size(0)\n",
        "            running_results['batch_sizes'] += batch_size\n",
        "    \n",
        "            ############################\n",
        "            # (1) Update D network: maximize D(x)-1-D(G(z))\n",
        "            ###########################\n",
        "            real_img = Variable(target)\n",
        "            if torch.cuda.is_available():\n",
        "                real_img = real_img.cuda()\n",
        "            z = Variable(data)\n",
        "            if torch.cuda.is_available():\n",
        "                z = z.cuda()\n",
        "            fake_img = netG(z)\n",
        "    \n",
        "            netD.zero_grad()\n",
        "            real_out = netD(real_img).mean()\n",
        "            fake_out = netD(fake_img).mean()\n",
        "            d_loss = 1 - real_out + fake_out\n",
        "            d_loss.backward(retain_graph=True)\n",
        "            optimizerD.step()\n",
        "    \n",
        "            ############################\n",
        "            # (2) Update G network: minimize 1-D(G(z)) + Perception Loss + Image Loss + TV Loss\n",
        "            ###########################\n",
        "            netG.zero_grad()\n",
        "            ## The two lines below are added to prevent runetime error in Google Colab ##\n",
        "            fake_img = netG(z)\n",
        "            fake_out = netD(fake_img).mean()\n",
        "            ##\n",
        "            g_loss = generator_criterion(fake_out, fake_img, real_img)\n",
        "            g_loss.backward()\n",
        "            \n",
        "            fake_img = netG(z)\n",
        "            fake_out = netD(fake_img).mean()\n",
        "            \n",
        "            \n",
        "            optimizerG.step()\n",
        "\n",
        "            # loss for current batch before optimization \n",
        "            running_results['g_loss'] += g_loss.item() * batch_size\n",
        "            running_results['d_loss'] += d_loss.item() * batch_size\n",
        "            running_results['d_score'] += real_out.item() * batch_size\n",
        "            running_results['g_score'] += fake_out.item() * batch_size\n",
        "    \n",
        "            train_bar.set_description(desc='[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f' % (\n",
        "                epoch, num_epochs, running_results['d_loss'] / running_results['batch_sizes'],\n",
        "                running_results['g_loss'] / running_results['batch_sizes'],\n",
        "                running_results['d_score'] / running_results['batch_sizes'],\n",
        "                running_results['g_score'] / running_results['batch_sizes']))\n",
        "    \n",
        "        netG.eval()\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            val_bar = tqdm(val_loader)\n",
        "            valid_results = {'mse': 0, 'ssims': 0, 'psnr': 0, 'ssim': 0, 'batch_sizes': 0}\n",
        "            val_images = []\n",
        "            for val_lr, val_hr_restore, val_hr in val_bar:\n",
        "                batch_size = val_lr.size(0)\n",
        "                valid_results['batch_sizes'] += batch_size\n",
        "                lr = val_lr\n",
        "                hr = val_hr\n",
        "                if torch.cuda.is_available():\n",
        "                    lr = lr.cuda()\n",
        "                    hr = hr.cuda()\n",
        "                sr = netG(lr)\n",
        "        \n",
        "                batch_mse = ((sr - hr) ** 2).data.mean()\n",
        "                valid_results['mse'] += batch_mse * batch_size\n",
        "                batch_ssim = ssim(sr, hr).item()\n",
        "                valid_results['ssims'] += batch_ssim * batch_size\n",
        "                valid_results['psnr'] = 10 * math.log10((hr.max()**2) / (valid_results['mse'] / valid_results['batch_sizes']))\n",
        "                valid_results['ssim'] = valid_results['ssims'] / valid_results['batch_sizes']\n",
        "                val_bar.set_description(\n",
        "                    desc='[converting LR images to SR images] PSNR: %.4f dB SSIM: %.4f' % (\n",
        "                        valid_results['psnr'], valid_results['ssim']))\n",
        "        \n",
        "        if not os.path.exists('epochs/'):\n",
        "          os.makedirs('epochs/')\n",
        "        # save model parameters\n",
        "        if epoch%10==0:\n",
        "          torch.save(netG.state_dict(), 'epochs/netG_epoch_%d_%d.pth' % (upscale_factor, epoch))\n",
        "          torch.save(netD.state_dict(), 'epochs/netD_epoch_%d_%d.pth' % (upscale_factor, epoch))\n",
        "        # save loss\\scores\\psnr\\ssim\n",
        "        results['d_loss'].append(running_results['d_loss'] / running_results['batch_sizes'])\n",
        "        results['g_loss'].append(running_results['g_loss'] / running_results['batch_sizes'])\n",
        "        results['d_score'].append(running_results['d_score'] / running_results['batch_sizes'])\n",
        "        results['g_score'].append(running_results['g_score'] / running_results['batch_sizes'])\n",
        "        results['psnr'].append(valid_results['psnr'])\n",
        "        results['ssim'].append(valid_results['ssim'])\n",
        "    \n",
        "        if epoch % 10 == 0 and epoch != 0:\n",
        "            out_path = 'statistics/'\n",
        "            if not os.path.exists(out_path):\n",
        "              os.makedirs(out_path)\n",
        "            \n",
        "            data_frame = pd.DataFrame(\n",
        "                data={'Loss_D': results['d_loss'], 'Loss_G': results['g_loss'], 'Score_D': results['d_score'],\n",
        "                      'Score_G': results['g_score'], 'PSNR': results['psnr'], 'SSIM': results['ssim']},\n",
        "                index=range(1, epoch + 1))\n",
        "            data_frame.to_csv(out_path + 'srf_' + str(upscale_factor) + '_train_results.csv', index_label='Epoch')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cF3E56Tx06lL"
      },
      "source": [
        "#### Evaluating on test image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_aeYGeDub1F",
        "outputId": "6cce4b1e-f3a5-4440-acd7-28da95c02fb5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "upscale_factor = 8\n",
        "model_name = \"netG_epoch_8_20.pth\"\n",
        "model = Generator(upscale_factor).eval()\n",
        "model = model.to(device)\n",
        "model.load_state_dict(torch.load('epochs/' + model_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "rqNLuzs31VOk"
      },
      "outputs": [],
      "source": [
        "image_name= \"/content/input.jpeg\"\n",
        "image = Image.open(image_name)\n",
        "image = Variable(transforms.ToTensor()(image)).unsqueeze(0).to(device)\n",
        "out = model(image)\n",
        "out_img = transforms.ToPILImage()(out[0].data.cpu())\n",
        "out_img.save('output.jpeg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p28CpZGF9VPx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0cadf6a3b92f4a8f8c92e00cb8872bb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43e43d4b9e9c482386ef52b3618235c7",
            "placeholder": "​",
            "style": "IPY_MODEL_99e81c0524c540059435dec8c52b0470",
            "value": " 528M/528M [00:02&lt;00:00, 189MB/s]"
          }
        },
        "17f7320c1455408983858c70bba43185": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d33884835ce74b9492563872e137dee9",
              "IPY_MODEL_b9b0e111bfa1436db32808a43abbc0c9",
              "IPY_MODEL_0cadf6a3b92f4a8f8c92e00cb8872bb6"
            ],
            "layout": "IPY_MODEL_bc34302ea074489ab3a75048dfaad892"
          }
        },
        "43e43d4b9e9c482386ef52b3618235c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59cd79707c6d46ce9fe85cb4d1f6e562": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "75507366d54b4006ae015c433298aece": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99e81c0524c540059435dec8c52b0470": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9b0e111bfa1436db32808a43abbc0c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb4488196862488fab0ab286a3c57fd9",
            "max": 553433881,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59cd79707c6d46ce9fe85cb4d1f6e562",
            "value": 553433881
          }
        },
        "bc34302ea074489ab3a75048dfaad892": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d33884835ce74b9492563872e137dee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75507366d54b4006ae015c433298aece",
            "placeholder": "​",
            "style": "IPY_MODEL_fefd79ab244c471880fa6440a445d637",
            "value": "100%"
          }
        },
        "eb4488196862488fab0ab286a3c57fd9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fefd79ab244c471880fa6440a445d637": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
