{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About\n",
    "\n",
    "> Eigenvalues and Eigenvectors\n",
    "\n",
    "In linear algebra, an eigenvector of a square matrix is a non-zero vector that, when multiplied by the matrix, results in a scalar multiple of the original vector. This scalar multiple is called the eigenvalue of the matrix. In other words, if A is a square matrix, a non-zero vector v is an eigenvector of A if and only if Av = λv, where λ is a scalar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[4, 2], [3, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute eigenvectors and eigenvalues\n",
    "eigenvals, eigenvects = np.linalg.eig(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues:  [ 5.37228132 -0.37228132]\n",
      "Eigenvectors:  [[ 0.82456484 -0.41597356]\n",
      " [ 0.56576746  0.90937671]]\n"
     ]
    }
   ],
   "source": [
    "# Print the eigenvectors and eigenvalues\n",
    "print(\"Eigenvalues: \", eigenvals)\n",
    "print(\"Eigenvectors: \", eigenvects)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eigenvectors and eigenvalues of a matrix have many important applications in various fields. One common application is in data analysis and dimensionality reduction. In particular, principal component analysis (PCA) is a technique that uses eigenvectors and eigenvalues to identify the most important features of a dataset and reduce its dimensionality.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, suppose you have a dataset with many features (columns) and you want to reduce it to a smaller set of features that capture most of the variation in the data. You can use PCA to compute the eigenvectors and eigenvalues of the covariance matrix of the data, and then select the top eigenvectors (those with the highest eigenvalues) as the new set of features. This can help simplify the data and improve the performance of machine learning algorithms that are applied to the data.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
