{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About\n",
    "\n",
    "> Model Deployment in kubeflow\n",
    "\n",
    "- Deploying trained model as a service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a trained TensorFlow model saved in a directory\n",
    "model_directory = \"/path/to/your/model\"\n",
    "\n",
    "# Install TensorFlow Serving\n",
    "!pip install tensorflow-serving-api\n",
    "\n",
    "# Deploy the model using TensorFlow Serving\n",
    "!tensorflow_model_server --model_base_path={model_directory} --rest_api_port=8501 --model_name=your_model_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuring model serving components:\n",
    "Assuming we have a YAML configuration file (deployment_config.yaml) for Kubeflow deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiVersion: \"serving.kubeflow.org/v1alpha2\"\n",
    "kind: \"InferenceService\"\n",
    "metadata:\n",
    "  name: \"your-model-name\"\n",
    "spec:\n",
    "  default:\n",
    "    predictor:\n",
    "      tensorflow:\n",
    "        storageUri: \"s3://your-bucket/your-model-path\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the model with the configuration:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl apply -f deployment_config.yaml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Model Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling model versioning and updates:\n",
    "Assuming we have an updated version of your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a new version of your trained TensorFlow model\n",
    "new_model_directory = \"/path/to/your/new_model\"\n",
    "\n",
    "# Deploy the updated model using TensorFlow Serving\n",
    "!tensorflow_model_server --model_base_path={new_model_directory} --rest_api_port=8502 --model_name=your_model_name_v2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To switch to the new version:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiVersion: \"serving.kubeflow.org/v1alpha2\"\n",
    "kind: \"InferenceService\"\n",
    "metadata:\n",
    "  name: \"your-model-name\"\n",
    "spec:\n",
    "  default:\n",
    "    predictor:\n",
    "      tensorflow:\n",
    "        storageUri: \"s3://your-bucket/your-new-model-path\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the updated configuration:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl apply -f updated_deployment_config.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kubeflow will handle scaling, but ensure we have configured resources in our deployment YAML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiVersion: \"serving.kubeflow.org/v1alpha2\"\n",
    "kind: \"InferenceService\"\n",
    "metadata:\n",
    "  name: \"your-model-name\"\n",
    "spec:\n",
    "  predictor:\n",
    "    tensorflow:\n",
    "      resources:\n",
    "        requests:\n",
    "          memory: \"1Gi\"\n",
    "          cpu: \"1\"\n",
    "        limits:\n",
    "          memory: \"2Gi\"\n",
    "          cpu: \"2\"\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
