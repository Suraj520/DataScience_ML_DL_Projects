{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About\n",
    "\n",
    "> Data pipelines\n",
    "\n",
    "A data pipeline is a series of operations that move data from one place to another, often involving transformation and processing. The goal of a data pipeline is to take raw data and turn it into valuable insights for business decision making. \n",
    "\n",
    "1. Batch pipeline: It involves processing large amount of data simultaneously. It involves taking large data sets, processing them all at once and outputting the results. Batch processing is often used for data that does not need to be processed in real time, such as financial statements or historical analysis. \n",
    "\n",
    "2. Streaming pipelines: They are used to process incoming data in real-time. Data streams can be processed instantly and results read in real time. Streaming pipelines are often used in applications such as fraud detection, real-time analytics, and social media monitoring. 3. ETL (Extract, Transform, Load) pipeline: The ETL pipeline involves extracting data from one or more sources, transforming it into an appropriate format or structure, and loading it into the target system. This type of pipeline is often used to move data between systems, clean data, and integrate data from multiple sources.\n",
    "\n",
    "4. Machine Learning Pipeline: It involves taking raw data, preparing it for machine learning, training a model on the data, and then deploying the model to make predictions. Machine learning pipelines are commonly used in applications such as recommender systems, image recognition, and natural language processing. \n",
    "\n",
    "5. DevOps Pipeline: It involves automating the process of building, testing and deploying software. This type of pipeline is often used in software development projects that aim to quickly move code changes from a development environment to a production environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
