{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About\n",
    "\n",
    "> Role of training operators in kubeflow\n",
    "\n",
    "- Training ops in kubeflow play a crucial role in managing and orchestrating the training of ml models.\n",
    "\n",
    "- they act as specialized components that handle the training process, making it more efficient and scalable.\n",
    "\n",
    "[Reference Video](https://www.youtube.com/watch?v=fMXFbREG7Yg)\n",
    "\n",
    "> Let's explore an example using Katib and TFJob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define a complex TensorFlow model and training script\n",
    "# Assume you have a file called train_advanced.py\n",
    "\n",
    "# train_advanced.py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load and preprocess your training data\n",
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "    train_images, train_labels, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# Define a convolutional neural network\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=5, validation_data=(val_images, val_labels))\n",
    "\n",
    "# Save the trained model\n",
    "model.save('/output/model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create a Katib experiment YAML file for hyperparameter tuning\n",
    "# Assume you have a file called katib-experiment.yaml\n",
    "\n",
    "# katib-experiment.yaml\n",
    "apiVersion: \"kubeflow.org/v1beta1\"\n",
    "kind: Experiment\n",
    "metadata:\n",
    "  name: mnist-tuning\n",
    "spec:\n",
    "  maxTrialCount: 12\n",
    "  maxFailedTrialCount: 3\n",
    "  parallelTrialCount: 3\n",
    "  algorithm:\n",
    "    algorithmName: random\n",
    "  objective:\n",
    "    goal: 0.99\n",
    "    objectiveMetricName: accuracy\n",
    "    additionalMetricNames:\n",
    "      - loss\n",
    "  parameters:\n",
    "    - name: learning_rate\n",
    "      parameterType: double\n",
    "      feasibleSpace:\n",
    "        min: \"0.01\"\n",
    "        max: \"0.1\"\n",
    "    - name: batch_size\n",
    "      parameterType: int\n",
    "      feasibleSpace:\n",
    "        min: \"32\"\n",
    "        max: \"128\"\n",
    "    - name: dropout_rate\n",
    "      parameterType: double\n",
    "      feasibleSpace:\n",
    "        min: \"0.2\"\n",
    "        max: \"0.5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Modify the TFJob YAML file to use hyperparameters\n",
    "# Assume you have a file called tfjob_advanced.yaml\n",
    "\n",
    "# tfjob_advanced.yaml\n",
    "apiVersion: \"kubeflow.org/v1\"\n",
    "kind: \"TFJob\"\n",
    "metadata:\n",
    "  name: \"mnist-tfjob\"\n",
    "spec:\n",
    "  tfReplicaSpecs:\n",
    "    Chief:\n",
    "      replicas: 1\n",
    "      template:\n",
    "        spec:\n",
    "          containers:\n",
    "          - name: tensorflow\n",
    "            image: \"your-tensorflow-image:latest\"\n",
    "            command:\n",
    "              - \"python\"\n",
    "              - \"/mnt/train_advanced.py\"\n",
    "              - \"--learning_rate=${trialParameters.learningRate}\"\n",
    "              - \"--batch_size=${trialParameters.batchSize}\"\n",
    "              - \"--dropout_rate=${trialParameters.dropoutRate}\"\n",
    "            volumeMounts:\n",
    "              - name: data\n",
    "                mountPath: \"/mnt\"\n",
    "          volumes:\n",
    "            - name: data\n",
    "              persistentVolumeClaim:\n",
    "                claimName: \"your-data-pvc\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scripts Defn\n",
    "\n",
    "- The `train_advanced.py` script defines a convolutional neural network for image classification and includes data preprocessing.\n",
    "- `The katib-experiment.yaml` file sets up a Katib experiment for hyperparameter tuning, specifying parameters like learning rate, batch size, and dropout rate.\n",
    "- `The tfjob_advanced.yaml` file modifies the TFJob to use the hyperparameters provided by Katib during the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
