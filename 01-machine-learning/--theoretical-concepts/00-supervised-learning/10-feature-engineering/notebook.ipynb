{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About\n",
    "\n",
    "> Feature Engineering\n",
    "\n",
    "Feature engineering is the process of creating or selecting relevant and informative features from raw data to improve the performance and effectiveness of a supervised learning model. It involves transforming or manipulating the original features in the data to create new features that can better capture the underlying patterns or relationships in the data.\n",
    "\n",
    "Feature engineering is an important step in the machine learning pipeline as the quality and relevance of the features used as input to a model can significantly impact its performance.\n",
    "\n",
    "Let's consider a use case where we have a dataset of housing prices with the following features: 'area', 'bedrooms', 'bathrooms', 'age', and 'location', and the target variable 'price' indicating the price of the house. We can perform the following feature engineering steps:\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Feature scaling: We can scale the numerical features, such as 'area', 'bedrooms', 'bathrooms', and 'age', to a similar scale to avoid bias towards features with larger values. For example, we can use Min-Max scaling or Z-score normalization to scale the features to a common range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "## load the dataframe in df\n",
    "df = pd.read_csv('housing_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale the numerical features\n",
    "df['area'] = scaler.fit_transform(df['area'].values.reshape(-1, 1))\n",
    "df['bedrooms'] = scaler.fit_transform(df['bedrooms'].values.reshape(-1, 1))\n",
    "df['bathrooms'] = scaler.fit_transform(df['bathrooms'].values.reshape(-1, 1))\n",
    "df['age'] = scaler.fit_transform(df['age'].values.reshape(-1, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Feature encoding: We can encode categorical features, such as 'location', into numerical values to make them usable as input to a machine learning model. For example, we can use label encoding or one-hot encoding to convert categorical features into numerical representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Perform label encoding on the 'location' feature\n",
    "df['location'] = encoder.fit_transform(df['location'])\n",
    "\n",
    "# Alternatively, we can use one-hot encoding\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "location_one_hot = one_hot_encoder.fit_transform(df['location'].values.reshape(-1, 1)).toarray()\n",
    "\n",
    "# Create new one-hot encoded features\n",
    "for i in range(location_one_hot.shape[1]):\n",
    "    df['location_{}'.format(i)] = location_one_hot[:, i]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Feature interaction: We can create new features by combining or interacting existing features to capture higher-order relationships or interactions between them. For example, we can create a feature that represents the product of 'area' and 'age' to capture the interaction between the size of the house and its age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new feature 'area_age_interaction'\n",
    "df['area_age_interaction'] = df['area'] * df['age']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Feature transformation: We can apply mathematical or statistical transformations to the features to capture non-linear relationships or to make the features more suitable for the model. For example, we can apply logarithmic transformation or square root transformation to features with skewed distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Apply log transformation to the 'price' feature\n",
    "df['price'] = np.log(df['price'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Feature selection: We can select a subset of the most relevant features from the original set of features to reduce noise, improve model interpretability, and reduce computational complexity. For example, we can use feature importance techniques, such as tree-based feature importance or recursive feature elimination, to select the most important features.\n",
    "python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
