{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About\n",
    "\n",
    "> Cross Validation\n",
    "\n",
    "Cross-validation is a technique used in supervised machine learning to assess the performance and generalization ability of a model. It involves partitioning the dataset into multiple subsets or \"folds\", training the model on some folds and evaluating its performance on the remaining fold(s). This process is repeated multiple times with different fold combinations, and the results are averaged to obtain an overall performance estimate of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 1], [1, 0], [0, 1], [0, 0]]) #XOR\n",
    "y = np.array([0, 1, 1, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KFold cross-validator with 3 folds\n",
    "kf = KFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation\n",
    "scores = cross_val_score(model, X, y, cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores for each fold: [0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy scores for each fold\n",
    "print(\"Accuracy scores for each fold:\", scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy score: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Print the average accuracy score\n",
    "print(\"Average accuracy score:\", np.mean(scores))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Some use cases of cross-validation include:\n",
    "\n",
    "1. Model selection: Cross-validation can be used to compare the performance of different models or hyperparameter settings to select the best-performing one.\n",
    "\n",
    "2. Model evaluation: Cross-validation provides a more robust and reliable estimate of a model's performance by evaluating it on multiple subsets of the data.\n",
    "\n",
    "3. Data scarcity: Cross-validation can be useful when the dataset is small, as it allows for a more efficient use of limited data by leveraging multiple folds for training and evaluation.\n",
    "\n",
    "4. Overfitting detection: Cross-validation can help detect overfitting, as it provides an estimate of how well the model is likely to generalize to unseen data.\n",
    "\n",
    "5. Model fairness evaluation: Cross-validation can be used to assess the fairness of a model's predictions across different folds or subsets of the data, which is important for ethical machine learning.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
