{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About\n",
    "\n",
    "> K-Nearest Neighbours.\n",
    "\n",
    "The k-nearest neighbors (KNN) algorithm is a simple yet powerful supervised machine learning algorithm used for classification and regression tasks. It is a non-parametric, lazy learner algorithm that makes predictions by finding the k nearest neighbors to a given data point and making predictions based on the majority vote or weighted average of the labels of these neighbors.\n",
    "\n",
    "> Steps of the KNN algorithm\n",
    "\n",
    "1. Load the training dataset which consists of labelled data points with their corresponding labels.\n",
    "2. Choose the value of k: Determine the number of nearest neighbors (k) to consider for making predictions. This is a hyperparameter that needs to be tuned.\n",
    "3. Calculate distances: Calculate the distance between the test data point and all the training data points using a distance metric such as Euclidean distance, Manhattan distance, or Minkowski distance.\n",
    "4. Find k nearest neighbors: Select the k nearest neighbors to the test data point based on the calculated distances.\n",
    "5. Make predictions: For classification tasks, predict the class label of the test data point based on the majority vote of the labels of the k nearest neighbors. For regression tasks, predict the target value of the test data point based on the weighted average of the target values of the k nearest neighbors, where the weights are determined by the inverse of the distances.\n",
    "\n",
    "> Mathematics\n",
    "\n",
    "1. Distance Calculation:\n",
    "\n",
    "The most commonly used distance metric for KNN is the Euclidean distance, which is calculated as follows:\n",
    "\n",
    "Euclidean Distance = sqrt((x2 - x1)^2 + (y2 - y1)^2)  \n",
    "\n",
    "where (x1, y1) and (x2, y2) are the coordinates of two data points in a two-dimensional feature space.\n",
    "\n",
    "\n",
    "\n",
    "2. Majority Vote for Classification:\n",
    "\n",
    "For classification tasks, the majority vote of the labels of the k nearest neighbors is used to make predictions. The class with the highest count among the k nearest neighbors is selected as the predicted class label for the test data point.\n",
    "\n",
    "3. Weighted Average for Regression: For regression tasks, The weighted average of the target values of the k nearest neighbors is used to make predictions. The inverse of the distances between the test data point and the k nearest neighbors is used as the weights in the weighted average calculation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "classifier = KNeighborsClassifier(n_neighbors=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Train the KNN classifier on the training data\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
