{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About\n",
    "\n",
    "> Dimensionality Reduction\n",
    "\n",
    "Dimensionality reduction is a technique used to reduce the number of features or variables in a data set while preserving relevant information. Visualizing, analyzing, and modeling high-dimensional data can be challenging, and dimensionality reduction techniques help solve this problem by transforming the data into a lower-dimensional representation. There are two main types of size reduction techniques:\n",
    "\n",
    "1. Selection of means. Feature selection techniques involve selecting a subset of raw features or variables from a data set based on specific criteria, such as their importance or relevance to a given problem. These methods preserve the original features but discard some of them, resulting in a reduced size set.\n",
    "\n",
    "2. Feature extraction: Feature extraction techniques generate new features or variants from raw features using mathematical transformations. These methods create a new feature set that captures the most important information from the original features, resulting in a low-dimensional representation of the data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Commonly used Dimensionality reduction techniques\n",
    "\n",
    "1. Principal Component Analysis (PCA): PCA is a widely used linear dimensionality reduction technique that transforms the original features into a new set of uncorrelated features called principal components, which are ordered by their explained variance. PCA finds the directions in the data with the highest variance and projects the data onto these directions to create a lower-dimensional representation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199, 2324)\n"
     ]
    }
   ],
   "source": [
    "X = np.random.random((199,2324))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PCA instance with desired number of components\n",
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PCA(n_components=2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit PCA to the data\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199, 2)\n"
     ]
    }
   ],
   "source": [
    "# Transform the data to the first two principal components\n",
    "X_pca = pca.transform(X)\n",
    "\n",
    "print(X_pca.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. t-SNE (t-distributed Stochastic Neighbor Embedding): t-SNE is a nonlinear dimensionality reduction technique that is particularly useful for visualizing high-dimensional data in a low-dimensional space. It preserves the local structure of the data by minimizing the divergence between pairwise similarities in the original data and in the reduced-dimensional representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a t-SNE instance with desired number of components\n",
    "tsne = TSNE(n_components=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fit t-SNE to the data\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "print(X_tsne.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. LLE (Locally Linear Embedding): LLE is a nonlinear dimensionality reduction technique that assumes that the data lies on a locally linear manifold. It finds a lower-dimensional representation of the data by reconstructing each data point as a weighted linear combination of its neighbors in the original space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import LocallyLinearEmbedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an LLE instance with desired number of components\n",
    "lle = LocallyLinearEmbedding(n_components=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199, 6)\n"
     ]
    }
   ],
   "source": [
    "# Fit LLE to the data\n",
    "X_lle = lle.fit_transform(X)\n",
    "print(X_lle.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Autoencoders: Autoencoders are a type of neural network-based dimensionality reduction technique that consists of an encoder and a decoder. The encoder maps the original features to a lower-dimensional representation, and the decoder maps the lower-dimensional representation back to the original features. Autoencoders are trained to minimize the reconstruction error, which encourages the model to learn a meaningful lower-dimensional representation of the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 04:14:46.547370: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-21 04:14:46.609599: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-21 04:14:46.611876: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-21 04:14:48.180066: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input shape and the desired dimension of the encoded representation\n",
    "input_dim = X.shape[1]\n",
    "encoding_dim = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 04:14:54.113127: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-21 04:14:54.119070: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Define the encoder\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the decoder\n",
    "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the autoencoder model\n",
    "autoencoder = Model(input_layer, decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 9ms/step - loss: 0.6931\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6931\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6930\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6930\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6930\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6929\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6929\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6929\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6928\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6928\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6928\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6928\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6927\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6927\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6927\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6927\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6926\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6926\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6926\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6926\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6926\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6926\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6925\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6925\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6925\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6925\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6925\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6925\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6925\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6925\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6925\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6924\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6924\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6924\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6924\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6924\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6924\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6924\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6924\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6924\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6924\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6924\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6924\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6924\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6924\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6924\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6924\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6924\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6924\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6924\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6924\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6923\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6923\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6923\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6923\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6923\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6923\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6923\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6923\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6923\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6923\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6923\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6923\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6923\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6923\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6923\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6923\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6923\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6923\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6923\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6923\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6923\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6923\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6923\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6923\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6923\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6923\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6923\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6923\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6923\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6923\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6923\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6923\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6923\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6923\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6923\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6923\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6923\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6923\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6923\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6923\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6923\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6923\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6923\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6923\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6923\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6923\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6923\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6923\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5b881e3ca0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(X, X, epochs=100, batch_size=32) #train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step\n",
      "(199, 2324)\n"
     ]
    }
   ],
   "source": [
    "X_encoded = autoencoder.predict(X)\n",
    "print(X_encoded.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
